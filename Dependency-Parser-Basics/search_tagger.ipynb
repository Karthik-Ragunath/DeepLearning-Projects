{"cells":[{"cell_type":"code","source":["#! /bin/bash"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6242b4be-5bdd-45fe-9c89-5e0a9c8c40b0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh pip install BeautifulSoup4"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"351079ba-ee26-46ee-bc20-e92b0212534b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Requirement already satisfied: BeautifulSoup4 in /databricks/python3/lib/python3.7/site-packages (4.9.3)\nRequirement already satisfied: soupsieve&gt;1.2 in /databricks/python3/lib/python3.7/site-packages (from BeautifulSoup4) (2.2.1)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Requirement already satisfied: BeautifulSoup4 in /databricks/python3/lib/python3.7/site-packages (4.9.3)\nRequirement already satisfied: soupsieve&gt;1.2 in /databricks/python3/lib/python3.7/site-packages (from BeautifulSoup4) (2.2.1)\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh pip install word2number"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9d5b10ff-5ece-497b-9e9d-d14c90a8873e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Requirement already satisfied: word2number in /databricks/python3/lib/python3.7/site-packages (1.1)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Requirement already satisfied: word2number in /databricks/python3/lib/python3.7/site-packages (1.1)\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from word2number import w2n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"73c02234-9df9-442a-9cde-1bda9a77492d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["import pandas as pd\n# candidate_sentences = spark.read.format(\"csv\").load(\"dbfs:/FileStore/shared_uploads/t_karthik.ragunath@tatadigital.com/qa.csv\", delimiter='\\t', encoding='utf-8', index_col=0)\ncandidate_sentences = pd.read_csv(\"/dbfs/FileStore/shared_uploads/t_karthik.ragunath@tatadigital.com/qa.csv\", delimiter='\\t', encoding='utf-8', index_col=0)\ncheck_df = pd.read_csv(\"/dbfs/FileStore/shared_uploads/t_karthik.ragunath@tatadigital.com/data_cleanser.csv\",  header=0, delimiter='\\t', error_bad_lines=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f9726ab0-103f-4597-a7bd-8385de4e5fe8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">b&#39;Skipping line 1114: expected 1 fields, saw 2\\nSkipping line 2126: expected 1 fields, saw 2\\nSkipping line 2296: expected 1 fields, saw 2\\nSkipping line 4922: expected 1 fields, saw 2\\nSkipping line 9500: expected 1 fields, saw 2\\nSkipping line 12578: expected 1 fields, saw 2\\nSkipping line 15295: expected 1 fields, saw 2\\nSkipping line 18309: expected 1 fields, saw 2\\nSkipping line 21193: expected 1 fields, saw 2\\nSkipping line 24723: expected 1 fields, saw 2\\nSkipping line 35928: expected 1 fields, saw 2\\nSkipping line 38161: expected 1 fields, saw 2\\nSkipping line 47049: expected 1 fields, saw 2\\nSkipping line 51626: expected 1 fields, saw 2\\n&#39;\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">b&#39;Skipping line 1114: expected 1 fields, saw 2\\nSkipping line 2126: expected 1 fields, saw 2\\nSkipping line 2296: expected 1 fields, saw 2\\nSkipping line 4922: expected 1 fields, saw 2\\nSkipping line 9500: expected 1 fields, saw 2\\nSkipping line 12578: expected 1 fields, saw 2\\nSkipping line 15295: expected 1 fields, saw 2\\nSkipping line 18309: expected 1 fields, saw 2\\nSkipping line 21193: expected 1 fields, saw 2\\nSkipping line 24723: expected 1 fields, saw 2\\nSkipping line 35928: expected 1 fields, saw 2\\nSkipping line 38161: expected 1 fields, saw 2\\nSkipping line 47049: expected 1 fields, saw 2\\nSkipping line 51626: expected 1 fields, saw 2\\n&#39;\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#%sh pip install -U spacy"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"74d3dde9-52ca-4525-8f2e-f123e2f6cc84"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh pip install --upgrade --force-reinstall spacy==2.3.5"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2bb525c8-8069-4af0-93cd-220e3771b118"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Collecting spacy==2.3.5\n  Using cached spacy-2.3.5-cp37-cp37m-manylinux2014_x86_64.whl (10.4 MB)\nCollecting catalogue&lt;1.1.0,&gt;=0.0.7\n  Using cached catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\nCollecting tqdm&lt;5.0.0,&gt;=4.38.0\n  Using cached tqdm-4.60.0-py2.py3-none-any.whl (75 kB)\nCollecting murmurhash&lt;1.1.0,&gt;=0.28.0\n  Using cached murmurhash-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl (20 kB)\nCollecting preshed&lt;3.1.0,&gt;=3.0.2\n  Using cached preshed-3.0.5-cp37-cp37m-manylinux2014_x86_64.whl (126 kB)\nCollecting plac&lt;1.2.0,&gt;=0.9.6\n  Using cached plac-1.1.3-py2.py3-none-any.whl (20 kB)\nCollecting wasabi&lt;1.1.0,&gt;=0.4.0\n  Using cached wasabi-0.8.2-py3-none-any.whl (23 kB)\nCollecting cymem&lt;2.1.0,&gt;=2.0.2\n  Using cached cymem-2.0.5-cp37-cp37m-manylinux2014_x86_64.whl (35 kB)\nCollecting blis&lt;0.8.0,&gt;=0.4.0\n  Using cached blis-0.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.8 MB)\nCollecting thinc&lt;7.5.0,&gt;=7.4.1\n  Using cached thinc-7.4.5-cp37-cp37m-manylinux2014_x86_64.whl (1.0 MB)\nCollecting requests&lt;3.0.0,&gt;=2.13.0\n  Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB)\nCollecting numpy&gt;=1.15.0\n  Using cached numpy-1.20.2-cp37-cp37m-manylinux2010_x86_64.whl (15.3 MB)\nCollecting srsly&lt;1.1.0,&gt;=1.0.2\n  Using cached srsly-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl (184 kB)\nCollecting setuptools\n  Using cached setuptools-56.0.0-py3-none-any.whl (784 kB)\nCollecting importlib-metadata&gt;=0.20\n  Using cached importlib_metadata-4.0.1-py3-none-any.whl (16 kB)\nCollecting typing-extensions&gt;=3.6.4\n  Using cached typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\nCollecting zipp&gt;=0.5\n  Using cached zipp-3.4.1-py3-none-any.whl (5.2 kB)\nCollecting certifi&gt;=2017.4.17\n  Using cached certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\nCollecting chardet&lt;5,&gt;=3.0.2\n  Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\nCollecting idna&lt;3,&gt;=2.5\n  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\nCollecting urllib3&lt;1.27,&gt;=1.21.1\n  Using cached urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\nInstalling collected packages: zipp, typing-extensions, numpy, murmurhash, importlib-metadata, cymem, wasabi, urllib3, tqdm, srsly, preshed, plac, idna, chardet, certifi, catalogue, blis, thinc, setuptools, requests, spacy\n  Attempting uninstall: zipp\n    Found existing installation: zipp 3.4.1\n    Uninstalling zipp-3.4.1:\n      Successfully uninstalled zipp-3.4.1\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 3.10.0.0\n    Uninstalling typing-extensions-3.10.0.0:\n      Successfully uninstalled typing-extensions-3.10.0.0\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.20.2\n    Uninstalling numpy-1.20.2:\n      Successfully uninstalled numpy-1.20.2\n  Attempting uninstall: murmurhash\n    Found existing installation: murmurhash 1.0.5\n    Uninstalling murmurhash-1.0.5:\n      Successfully uninstalled murmurhash-1.0.5\n  Attempting uninstall: importlib-metadata\n    Found existing installation: importlib-metadata 4.0.1\n    Uninstalling importlib-metadata-4.0.1:\n      Successfully uninstalled importlib-metadata-4.0.1\n  Attempting uninstall: cymem\n    Found existing installation: cymem 2.0.5\n    Uninstalling cymem-2.0.5:\n      Successfully uninstalled cymem-2.0.5\n  Attempting uninstall: wasabi\n    Found existing installation: wasabi 0.8.2\n    Uninstalling wasabi-0.8.2:\n      Successfully uninstalled wasabi-0.8.2\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.26.4\n    Uninstalling urllib3-1.26.4:\n      Successfully uninstalled urllib3-1.26.4\n  Attempting uninstall: tqdm\n    Found existing installation: tqdm 4.60.0\n    Uninstalling tqdm-4.60.0:\n      Successfully uninstalled tqdm-4.60.0\n  Attempting uninstall: srsly\n    Found existing installation: srsly 2.4.1\n    Uninstalling srsly-2.4.1:\n      Successfully uninstalled srsly-2.4.1\n  Attempting uninstall: preshed\n    Found existing installation: preshed 3.0.5\n    Uninstalling preshed-3.0.5:\n      Successfully uninstalled preshed-3.0.5\n  Attempting uninstall: plac\n    Found existing installation: plac 1.1.3\n    Uninstalling plac-1.1.3:\n      Successfully uninstalled plac-1.1.3\n  Attempting uninstall: idna\n    Found existing installation: idna 2.10\n    Uninstalling idna-2.10:\n      Successfully uninstalled idna-2.10\n  Attempting uninstall: chardet\n    Found existing installation: chardet 4.0.0\n    Uninstalling chardet-4.0.0:\n      Successfully uninstalled chardet-4.0.0\n  Attempting uninstall: certifi\n    Found existing installation: certifi 2020.12.5\n    Uninstalling certifi-2020.12.5:\n      Successfully uninstalled certifi-2020.12.5\n  Attempting uninstall: catalogue\n    Found existing installation: catalogue 2.0.4\n    Uninstalling catalogue-2.0.4:\n      Successfully uninstalled catalogue-2.0.4\n  Attempting uninstall: blis\n    Found existing installation: blis 0.7.4\n    Uninstalling blis-0.7.4:\n      Successfully uninstalled blis-0.7.4\n  Attempting uninstall: thinc\n    Found existing installation: thinc 8.0.3\n    Uninstalling thinc-8.0.3:\n      Successfully uninstalled thinc-8.0.3\n  Attempting uninstall: setuptools\n    Found existing installation: setuptools 56.0.0\n    Uninstalling setuptools-56.0.0:\n      Successfully uninstalled setuptools-56.0.0\n  Attempting uninstall: requests\n    Found existing installation: requests 2.25.1\n    Uninstalling requests-2.25.1:\n      Successfully uninstalled requests-2.25.1\n  Attempting uninstall: spacy\n    Found existing installation: spacy 3.0.6\n    Uninstalling spacy-3.0.6:\n      Successfully uninstalled spacy-3.0.6\nERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nwayne-lib 0.1.0.dev5 requires requests==2.23.0, but you have requests 2.25.1 which is incompatible.\ntdl-connector 0.1.4 requires numpy==1.16.2, but you have numpy 1.20.2 which is incompatible.\nmadlib 0.1.10 requires certifi==2020.4.5.2, but you have certifi 2020.12.5 which is incompatible.\nmadlib 0.1.10 requires chardet==3.0.4, but you have chardet 4.0.0 which is incompatible.\nmadlib 0.1.10 requires idna==2.9, but you have idna 2.10 which is incompatible.\nmadlib 0.1.10 requires requests==2.23.0, but you have requests 2.25.1 which is incompatible.\nmadlib 0.1.10 requires urllib3==1.25.9, but you have urllib3 1.26.4 which is incompatible.\nen-core-web-sm 3.0.0 requires spacy&lt;3.1.0,&gt;=3.0.0, but you have spacy 2.3.5 which is incompatible.\nbotocore 1.13.50 requires urllib3&lt;1.26,&gt;=1.20; python_version &gt;= &#34;3.4&#34;, but you have urllib3 1.26.4 which is incompatible.\nalfred 1.3 requires boto3==1.3.0, but you have boto3 1.10.45 which is incompatible.\nalfred 1.3 requires botocore==1.4.8, but you have botocore 1.13.50 which is incompatible.\nalfred 1.3 requires docutils==0.12, but you have docutils 0.15.2 which is incompatible.\nalfred 1.3 requires futures==3.0.5, but you have futures 3.1.1 which is incompatible.\nalfred 1.3 requires jmespath==0.9.0, but you have jmespath 0.10.0 which is incompatible.\nalfred 1.3 requires python-dateutil==2.5.2, but you have python-dateutil 2.8.1 which is incompatible.\nalfred 1.3 requires redis==2.10.5, but you have redis 2.10.6 which is incompatible.\nalfred 1.3 requires six==1.10.0, but you have six 1.15.0 which is incompatible.\nSuccessfully installed blis-0.7.4 catalogue-1.0.0 certifi-2020.12.5 chardet-4.0.0 cymem-2.0.5 idna-2.10 importlib-metadata-4.0.1 murmurhash-1.0.5 numpy-1.20.2 plac-1.1.3 preshed-3.0.5 requests-2.25.1 setuptools-56.0.0 spacy-2.3.5 srsly-1.0.5 thinc-7.4.5 tqdm-4.60.0 typing-extensions-3.10.0.0 urllib3-1.26.4 wasabi-0.8.2 zipp-3.4.1\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Collecting spacy==2.3.5\n  Using cached spacy-2.3.5-cp37-cp37m-manylinux2014_x86_64.whl (10.4 MB)\nCollecting catalogue&lt;1.1.0,&gt;=0.0.7\n  Using cached catalogue-1.0.0-py2.py3-none-any.whl (7.7 kB)\nCollecting tqdm&lt;5.0.0,&gt;=4.38.0\n  Using cached tqdm-4.60.0-py2.py3-none-any.whl (75 kB)\nCollecting murmurhash&lt;1.1.0,&gt;=0.28.0\n  Using cached murmurhash-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl (20 kB)\nCollecting preshed&lt;3.1.0,&gt;=3.0.2\n  Using cached preshed-3.0.5-cp37-cp37m-manylinux2014_x86_64.whl (126 kB)\nCollecting plac&lt;1.2.0,&gt;=0.9.6\n  Using cached plac-1.1.3-py2.py3-none-any.whl (20 kB)\nCollecting wasabi&lt;1.1.0,&gt;=0.4.0\n  Using cached wasabi-0.8.2-py3-none-any.whl (23 kB)\nCollecting cymem&lt;2.1.0,&gt;=2.0.2\n  Using cached cymem-2.0.5-cp37-cp37m-manylinux2014_x86_64.whl (35 kB)\nCollecting blis&lt;0.8.0,&gt;=0.4.0\n  Using cached blis-0.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.8 MB)\nCollecting thinc&lt;7.5.0,&gt;=7.4.1\n  Using cached thinc-7.4.5-cp37-cp37m-manylinux2014_x86_64.whl (1.0 MB)\nCollecting requests&lt;3.0.0,&gt;=2.13.0\n  Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB)\nCollecting numpy&gt;=1.15.0\n  Using cached numpy-1.20.2-cp37-cp37m-manylinux2010_x86_64.whl (15.3 MB)\nCollecting srsly&lt;1.1.0,&gt;=1.0.2\n  Using cached srsly-1.0.5-cp37-cp37m-manylinux2014_x86_64.whl (184 kB)\nCollecting setuptools\n  Using cached setuptools-56.0.0-py3-none-any.whl (784 kB)\nCollecting importlib-metadata&gt;=0.20\n  Using cached importlib_metadata-4.0.1-py3-none-any.whl (16 kB)\nCollecting typing-extensions&gt;=3.6.4\n  Using cached typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\nCollecting zipp&gt;=0.5\n  Using cached zipp-3.4.1-py3-none-any.whl (5.2 kB)\nCollecting certifi&gt;=2017.4.17\n  Using cached certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\nCollecting chardet&lt;5,&gt;=3.0.2\n  Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\nCollecting idna&lt;3,&gt;=2.5\n  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\nCollecting urllib3&lt;1.27,&gt;=1.21.1\n  Using cached urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\nInstalling collected packages: zipp, typing-extensions, numpy, murmurhash, importlib-metadata, cymem, wasabi, urllib3, tqdm, srsly, preshed, plac, idna, chardet, certifi, catalogue, blis, thinc, setuptools, requests, spacy\n  Attempting uninstall: zipp\n    Found existing installation: zipp 3.4.1\n    Uninstalling zipp-3.4.1:\n      Successfully uninstalled zipp-3.4.1\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 3.10.0.0\n    Uninstalling typing-extensions-3.10.0.0:\n      Successfully uninstalled typing-extensions-3.10.0.0\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.20.2\n    Uninstalling numpy-1.20.2:\n      Successfully uninstalled numpy-1.20.2\n  Attempting uninstall: murmurhash\n    Found existing installation: murmurhash 1.0.5\n    Uninstalling murmurhash-1.0.5:\n      Successfully uninstalled murmurhash-1.0.5\n  Attempting uninstall: importlib-metadata\n    Found existing installation: importlib-metadata 4.0.1\n    Uninstalling importlib-metadata-4.0.1:\n      Successfully uninstalled importlib-metadata-4.0.1\n  Attempting uninstall: cymem\n    Found existing installation: cymem 2.0.5\n    Uninstalling cymem-2.0.5:\n      Successfully uninstalled cymem-2.0.5\n  Attempting uninstall: wasabi\n    Found existing installation: wasabi 0.8.2\n    Uninstalling wasabi-0.8.2:\n      Successfully uninstalled wasabi-0.8.2\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.26.4\n    Uninstalling urllib3-1.26.4:\n      Successfully uninstalled urllib3-1.26.4\n  Attempting uninstall: tqdm\n    Found existing installation: tqdm 4.60.0\n    Uninstalling tqdm-4.60.0:\n      Successfully uninstalled tqdm-4.60.0\n  Attempting uninstall: srsly\n    Found existing installation: srsly 2.4.1\n    Uninstalling srsly-2.4.1:\n      Successfully uninstalled srsly-2.4.1\n  Attempting uninstall: preshed\n    Found existing installation: preshed 3.0.5\n    Uninstalling preshed-3.0.5:\n      Successfully uninstalled preshed-3.0.5\n  Attempting uninstall: plac\n    Found existing installation: plac 1.1.3\n    Uninstalling plac-1.1.3:\n      Successfully uninstalled plac-1.1.3\n  Attempting uninstall: idna\n    Found existing installation: idna 2.10\n    Uninstalling idna-2.10:\n      Successfully uninstalled idna-2.10\n  Attempting uninstall: chardet\n    Found existing installation: chardet 4.0.0\n    Uninstalling chardet-4.0.0:\n      Successfully uninstalled chardet-4.0.0\n  Attempting uninstall: certifi\n    Found existing installation: certifi 2020.12.5\n    Uninstalling certifi-2020.12.5:\n      Successfully uninstalled certifi-2020.12.5\n  Attempting uninstall: catalogue\n    Found existing installation: catalogue 2.0.4\n    Uninstalling catalogue-2.0.4:\n      Successfully uninstalled catalogue-2.0.4\n  Attempting uninstall: blis\n    Found existing installation: blis 0.7.4\n    Uninstalling blis-0.7.4:\n      Successfully uninstalled blis-0.7.4\n  Attempting uninstall: thinc\n    Found existing installation: thinc 8.0.3\n    Uninstalling thinc-8.0.3:\n      Successfully uninstalled thinc-8.0.3\n  Attempting uninstall: setuptools\n    Found existing installation: setuptools 56.0.0\n    Uninstalling setuptools-56.0.0:\n      Successfully uninstalled setuptools-56.0.0\n  Attempting uninstall: requests\n    Found existing installation: requests 2.25.1\n    Uninstalling requests-2.25.1:\n      Successfully uninstalled requests-2.25.1\n  Attempting uninstall: spacy\n    Found existing installation: spacy 3.0.6\n    Uninstalling spacy-3.0.6:\n      Successfully uninstalled spacy-3.0.6\nERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nwayne-lib 0.1.0.dev5 requires requests==2.23.0, but you have requests 2.25.1 which is incompatible.\ntdl-connector 0.1.4 requires numpy==1.16.2, but you have numpy 1.20.2 which is incompatible.\nmadlib 0.1.10 requires certifi==2020.4.5.2, but you have certifi 2020.12.5 which is incompatible.\nmadlib 0.1.10 requires chardet==3.0.4, but you have chardet 4.0.0 which is incompatible.\nmadlib 0.1.10 requires idna==2.9, but you have idna 2.10 which is incompatible.\nmadlib 0.1.10 requires requests==2.23.0, but you have requests 2.25.1 which is incompatible.\nmadlib 0.1.10 requires urllib3==1.25.9, but you have urllib3 1.26.4 which is incompatible.\nen-core-web-sm 3.0.0 requires spacy&lt;3.1.0,&gt;=3.0.0, but you have spacy 2.3.5 which is incompatible.\nbotocore 1.13.50 requires urllib3&lt;1.26,&gt;=1.20; python_version &gt;= &#34;3.4&#34;, but you have urllib3 1.26.4 which is incompatible.\nalfred 1.3 requires boto3==1.3.0, but you have boto3 1.10.45 which is incompatible.\nalfred 1.3 requires botocore==1.4.8, but you have botocore 1.13.50 which is incompatible.\nalfred 1.3 requires docutils==0.12, but you have docutils 0.15.2 which is incompatible.\nalfred 1.3 requires futures==3.0.5, but you have futures 3.1.1 which is incompatible.\nalfred 1.3 requires jmespath==0.9.0, but you have jmespath 0.10.0 which is incompatible.\nalfred 1.3 requires python-dateutil==2.5.2, but you have python-dateutil 2.8.1 which is incompatible.\nalfred 1.3 requires redis==2.10.5, but you have redis 2.10.6 which is incompatible.\nalfred 1.3 requires six==1.10.0, but you have six 1.15.0 which is incompatible.\nSuccessfully installed blis-0.7.4 catalogue-1.0.0 certifi-2020.12.5 chardet-4.0.0 cymem-2.0.5 idna-2.10 importlib-metadata-4.0.1 murmurhash-1.0.5 numpy-1.20.2 plac-1.1.3 preshed-3.0.5 requests-2.25.1 setuptools-56.0.0 spacy-2.3.5 srsly-1.0.5 thinc-7.4.5 tqdm-4.60.0 typing-extensions-3.10.0.0 urllib3-1.26.4 wasabi-0.8.2 zipp-3.4.1\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh pip install -U pip setuptools wheel"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"507a4e80-a3ae-42cf-9809-6c0d3fd420aa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Requirement already satisfied: pip in /databricks/python3/lib/python3.7/site-packages (21.1.1)\nRequirement already satisfied: setuptools in /databricks/python3/lib/python3.7/site-packages (56.0.0)\nRequirement already satisfied: wheel in /databricks/python3/lib/python3.7/site-packages (0.36.2)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Requirement already satisfied: pip in /databricks/python3/lib/python3.7/site-packages (21.1.1)\nRequirement already satisfied: setuptools in /databricks/python3/lib/python3.7/site-packages (56.0.0)\nRequirement already satisfied: wheel in /databricks/python3/lib/python3.7/site-packages (0.36.2)\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh python -m spacy download en_core_web_sm"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5e0b8a38-6c21-407d-b694-ef2809e700ef"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Collecting en_core_web_sm==2.3.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\nRequirement already satisfied: spacy&lt;2.4.0,&gt;=2.3.0 in /databricks/python3/lib/python3.7/site-packages (from en_core_web_sm==2.3.1) (2.3.5)\nRequirement already satisfied: catalogue&lt;1.1.0,&gt;=0.0.7 in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (1.0.0)\nRequirement already satisfied: tqdm&lt;5.0.0,&gt;=4.38.0 in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (4.60.0)\nRequirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (1.0.5)\nRequirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (3.0.5)\nRequirement already satisfied: plac&lt;1.2.0,&gt;=0.9.6 in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (1.1.3)\nRequirement already satisfied: wasabi&lt;1.1.0,&gt;=0.4.0 in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (0.8.2)\nRequirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (2.0.5)\nRequirement already satisfied: blis&lt;0.8.0,&gt;=0.4.0 in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (0.7.4)\nRequirement already satisfied: thinc&lt;7.5.0,&gt;=7.4.1 in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (7.4.5)\nRequirement already satisfied: requests&lt;3.0.0,&gt;=2.13.0 in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (2.25.1)\nRequirement already satisfied: numpy&gt;=1.15.0 in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (1.20.2)\nRequirement already satisfied: srsly&lt;1.1.0,&gt;=1.0.2 in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (1.0.5)\nRequirement already satisfied: setuptools in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (56.0.0)\nRequirement already satisfied: importlib-metadata&gt;=0.20 in /databricks/python3/lib/python3.7/site-packages (from catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (4.0.1)\nRequirement already satisfied: typing-extensions&gt;=3.6.4 in /databricks/python3/lib/python3.7/site-packages (from importlib-metadata&gt;=0.20-&gt;catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (3.10.0.0)\nRequirement already satisfied: zipp&gt;=0.5 in /databricks/python3/lib/python3.7/site-packages (from importlib-metadata&gt;=0.20-&gt;catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (3.4.1)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.7/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.7/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (4.0.0)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.7/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (2.10)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.7/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (1.26.4)\nBuilding wheels for collected packages: en-core-web-sm\n  Building wheel for en-core-web-sm (setup.py): started\n  Building wheel for en-core-web-sm (setup.py): finished with status &#39;done&#39;\n  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.3.1-py3-none-any.whl size=12047106 sha256=8d59da7582e0faaa9a8ecabe246b7060ebef75b6825f96946bff3505f283f8c6\n  Stored in directory: /tmp/pip-ephem-wheel-cache-d6nlgg5b/wheels/b7/0d/f0/7ecae8427c515065d75410989e15e5785dd3975fe06e795cd9\nSuccessfully built en-core-web-sm\nInstalling collected packages: en-core-web-sm\n  Attempting uninstall: en-core-web-sm\n    Found existing installation: en-core-web-sm 3.0.0\n    Uninstalling en-core-web-sm-3.0.0:\n      Successfully uninstalled en-core-web-sm-3.0.0\nSuccessfully installed en-core-web-sm-2.3.1\n<span class=\"ansi-green-fg\">✔ Download and installation successful</span>\nYou can now load the model via spacy.load(&#39;en_core_web_sm&#39;)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Collecting en_core_web_sm==2.3.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\nRequirement already satisfied: spacy&lt;2.4.0,&gt;=2.3.0 in /databricks/python3/lib/python3.7/site-packages (from en_core_web_sm==2.3.1) (2.3.5)\nRequirement already satisfied: catalogue&lt;1.1.0,&gt;=0.0.7 in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (1.0.0)\nRequirement already satisfied: tqdm&lt;5.0.0,&gt;=4.38.0 in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (4.60.0)\nRequirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (1.0.5)\nRequirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (3.0.5)\nRequirement already satisfied: plac&lt;1.2.0,&gt;=0.9.6 in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (1.1.3)\nRequirement already satisfied: wasabi&lt;1.1.0,&gt;=0.4.0 in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (0.8.2)\nRequirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (2.0.5)\nRequirement already satisfied: blis&lt;0.8.0,&gt;=0.4.0 in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (0.7.4)\nRequirement already satisfied: thinc&lt;7.5.0,&gt;=7.4.1 in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (7.4.5)\nRequirement already satisfied: requests&lt;3.0.0,&gt;=2.13.0 in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (2.25.1)\nRequirement already satisfied: numpy&gt;=1.15.0 in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (1.20.2)\nRequirement already satisfied: srsly&lt;1.1.0,&gt;=1.0.2 in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (1.0.5)\nRequirement already satisfied: setuptools in /databricks/python3/lib/python3.7/site-packages (from spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (56.0.0)\nRequirement already satisfied: importlib-metadata&gt;=0.20 in /databricks/python3/lib/python3.7/site-packages (from catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (4.0.1)\nRequirement already satisfied: typing-extensions&gt;=3.6.4 in /databricks/python3/lib/python3.7/site-packages (from importlib-metadata&gt;=0.20-&gt;catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (3.10.0.0)\nRequirement already satisfied: zipp&gt;=0.5 in /databricks/python3/lib/python3.7/site-packages (from importlib-metadata&gt;=0.20-&gt;catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (3.4.1)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.7/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.7/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (4.0.0)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.7/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (2.10)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.7/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy&lt;2.4.0,&gt;=2.3.0-&gt;en_core_web_sm==2.3.1) (1.26.4)\nBuilding wheels for collected packages: en-core-web-sm\n  Building wheel for en-core-web-sm (setup.py): started\n  Building wheel for en-core-web-sm (setup.py): finished with status &#39;done&#39;\n  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.3.1-py3-none-any.whl size=12047106 sha256=8d59da7582e0faaa9a8ecabe246b7060ebef75b6825f96946bff3505f283f8c6\n  Stored in directory: /tmp/pip-ephem-wheel-cache-d6nlgg5b/wheels/b7/0d/f0/7ecae8427c515065d75410989e15e5785dd3975fe06e795cd9\nSuccessfully built en-core-web-sm\nInstalling collected packages: en-core-web-sm\n  Attempting uninstall: en-core-web-sm\n    Found existing installation: en-core-web-sm 3.0.0\n    Uninstalling en-core-web-sm-3.0.0:\n      Successfully uninstalled en-core-web-sm-3.0.0\nSuccessfully installed en-core-web-sm-2.3.1\n<span class=\"ansi-green-fg\">✔ Download and installation successful</span>\nYou can now load the model via spacy.load(&#39;en_core_web_sm&#39;)\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh pip install networkx"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dfdd2b6c-d797-409d-95c2-1e515598da94"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Requirement already satisfied: networkx in /databricks/python3/lib/python3.7/site-packages (2.5.1)\nRequirement already satisfied: decorator&lt;5,&gt;=4.3 in /databricks/python3/lib/python3.7/site-packages (from networkx) (4.4.1)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Requirement already satisfied: networkx in /databricks/python3/lib/python3.7/site-packages (2.5.1)\nRequirement already satisfied: decorator&lt;5,&gt;=4.3 in /databricks/python3/lib/python3.7/site-packages (from networkx) (4.4.1)\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import re\nimport pandas as pd\nimport bs4\nimport requests\nimport spacy\nfrom spacy import displacy\nnlp = spacy.load('en_core_web_sm')\n\nfrom spacy.matcher import Matcher \nfrom spacy.tokens import Span \n\nimport networkx as nx\n\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\npd.set_option('display.max_colwidth', 200)\n%matplotlib inline"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f28d2a9a-d0a7-4985-8f04-97d3fc309a84"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["candidate_sentences['Query'] = candidate_sentences['Query'].fillna('')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3d3a23e0-2e98-4c48-a7bd-dd4c8c4cb323"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["color_dataset = pd.read_csv(\"/dbfs/FileStore/shared_uploads/t_karthik.ragunath@tatadigital.com/colours_rgb_shades.csv\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"52faabe9-710c-486b-8681-3dbe22fbe22d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["color_dataset['Color Name'] = color_dataset['Color Name'].fillna('')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dd8bc9ce-323b-460e-9d57-7828e2a55fd0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["color_names = []\nfor color in color_dataset['Color Name']:\n    color_names.append(''.join(' ' + c if c.isupper() else c for c in color).lower().strip())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d528cd7d-9a34-4ce8-8ae6-31d159db3fa5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["color_dataset['Color Names Cleaned'] = color_names\ncolor_dataset['Color Names Cleaned'][:10]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8e595bdf-ce6f-45be-bd55-75fb2d2c45ac"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[16]: 0                grey\n1       grey,  silver\n2                grey\n3          light gray\n4    light slate grey\n5          slate gray\n6         slate gray1\n7         slate gray2\n8         slate gray3\n9         slate gray4\nName: Color Names Cleaned, dtype: object</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[16]: 0                grey\n1       grey,  silver\n2                grey\n3          light gray\n4    light slate grey\n5          slate gray\n6         slate gray1\n7         slate gray2\n8         slate gray3\n9         slate gray4\nName: Color Names Cleaned, dtype: object</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from collections import defaultdict\ncheck_df = pd.read_csv(\"/dbfs/FileStore/shared_uploads/t_karthik.ragunath@tatadigital.com/data_cleanser.csv\",  header=0, delimiter='\\t', error_bad_lines=False)\ncheck_df['data_checker'] = check_df['data_checker'].fillna('')\ndata_checker_list = list(check_df['data_checker'])\nmax_len = 0\nfor ind_data in data_checker_list:\n    comma_sep_data = ind_data.split(',')\n    for datum in comma_sep_data:\n        datum = ' '.join(datum.split())\n        try:\n            length = len(datum.split(' '))\n        except:\n            print(datum, comma_sep_data)\n        if length > max_len:\n            max_len = length\n\ndata_checker_dict = defaultdict(set)\ndata_checker_set = set(data_checker_list)\nwords_to_remove = ['Dress', 'Skirt', 'Black']\ndata_checker_set = set(filter(lambda x:(len(x)!=1 and x not in words_to_remove), data_checker_set))\nfor ind_data in data_checker_list:\n    comma_sep_data = ind_data.split(',')\n    for datum in comma_sep_data:\n        datum = ' '.join(datum.split())\n        datum_split = datum.split(' ')\n        length = len(datum_split)\n        initial_key = \"\"\n        for i in range(length):\n            data_checker_dict[initial_key].add(' '.join(datum_split[0:(i + 1)]))\n            initial_key = ' '.join(datum_split[0:(i + 1)])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"db9d893d-2f1f-4de4-a022-b377d603c09e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">b&#39;Skipping line 1114: expected 1 fields, saw 2\\nSkipping line 2126: expected 1 fields, saw 2\\nSkipping line 2296: expected 1 fields, saw 2\\nSkipping line 4922: expected 1 fields, saw 2\\nSkipping line 9500: expected 1 fields, saw 2\\nSkipping line 12578: expected 1 fields, saw 2\\nSkipping line 15295: expected 1 fields, saw 2\\nSkipping line 18309: expected 1 fields, saw 2\\nSkipping line 21193: expected 1 fields, saw 2\\nSkipping line 24723: expected 1 fields, saw 2\\nSkipping line 35928: expected 1 fields, saw 2\\nSkipping line 38161: expected 1 fields, saw 2\\nSkipping line 47049: expected 1 fields, saw 2\\nSkipping line 51626: expected 1 fields, saw 2\\n&#39;\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">b&#39;Skipping line 1114: expected 1 fields, saw 2\\nSkipping line 2126: expected 1 fields, saw 2\\nSkipping line 2296: expected 1 fields, saw 2\\nSkipping line 4922: expected 1 fields, saw 2\\nSkipping line 9500: expected 1 fields, saw 2\\nSkipping line 12578: expected 1 fields, saw 2\\nSkipping line 15295: expected 1 fields, saw 2\\nSkipping line 18309: expected 1 fields, saw 2\\nSkipping line 21193: expected 1 fields, saw 2\\nSkipping line 24723: expected 1 fields, saw 2\\nSkipping line 35928: expected 1 fields, saw 2\\nSkipping line 38161: expected 1 fields, saw 2\\nSkipping line 47049: expected 1 fields, saw 2\\nSkipping line 51626: expected 1 fields, saw 2\\n&#39;\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["max_len = 0\nfor ind_color in color_names:\n    comma_sep_colors = ind_color.split(',')\n    for color in comma_sep_colors:\n        color = ' '.join(color.split())\n        try:\n            length = len(color.split(' '))\n        except:\n            print(color, comma_sep_colors)\n        if length > max_len:\n            max_len = length\n\ncolor_dictionary = defaultdict(set)\ncolor_set = set(color_names)\nfor ind_color in color_names:\n    comma_sep_colors = ind_color.split(',')\n    for color in comma_sep_colors:\n        color = ' '.join(color.split())\n        split_color = color.split(' ')\n        length = len(split_color)\n        initial_key = \"\"\n        for i in range(length):\n            color_dictionary[initial_key].add(' '.join(split_color[0:(i + 1)]))\n            initial_key = ' '.join(split_color[0:(i + 1)])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"954cd06f-5dcc-4676-9601-9bb8dcba4826"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["check_df['data_checker'][:10]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c653e56f-6610-4cdc-9562-b5cf53931f78"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[19]: 0           Gymboree\n1    E-Land American\n2               Soma\n3    JoJo Maman Bebe\n4       Abercrombie \n5        Souris Mini\n6     Janie and Jack\n7               Puma\n8             Merona\n9     CCH Collection\nName: data_checker, dtype: object</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[19]: 0           Gymboree\n1    E-Land American\n2               Soma\n3    JoJo Maman Bebe\n4       Abercrombie \n5        Souris Mini\n6     Janie and Jack\n7               Puma\n8             Merona\n9     CCH Collection\nName: data_checker, dtype: object</div>"]}}],"execution_count":0},{"cell_type":"code","source":["len(data_checker_set)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2d8b1b8a-30ef-402e-a993-450030acf1a4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[20]: 54741</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[20]: 54741</div>"]}}],"execution_count":0},{"cell_type":"code","source":["len(data_checker_dict.keys())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2b8fc792-609e-4737-8277-6632d7c4aee7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[21]: 33574</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[21]: 33574</div>"]}}],"execution_count":0},{"cell_type":"code","source":["(color_dictionary.keys())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"379f5440-8a19-418a-9238-5203d912343e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[22]: dict_keys([&#39;&#39;, &#39;light&#39;, &#39;light slate&#39;, &#39;slate&#39;, &#39;dim&#39;, &#39;dark&#39;, &#39;dark slate&#39;, &#39;very&#39;, &#39;very light&#39;, &#39;free&#39;, &#39;free speech&#39;, &#39;alice&#39;, &#39;blue&#39;, &#39;cadet&#39;, &#39;corn&#39;, &#39;corn flower&#39;, &#39;cornflower&#39;, &#39;deep&#39;, &#39;deep sky&#39;, &#39;dodger&#39;, &#39;light sky&#39;, &#39;light steel&#39;, &#39;medium&#39;, &#39;medium slate&#39;, &#39;midnight&#39;, &#39;navy&#39;, &#39;pale&#39;, &#39;powder&#39;, &#39;royal&#39;, &#39;sky&#39;, &#39;steel&#39;, &#39;true&#39;, &#39;true iris&#39;, &#39;neon&#39;, &#39;new&#39;, &#39;new midnight&#39;, &#39;rich&#39;, &#39;summer&#39;, &#39;iris&#39;, &#39;rosy&#39;, &#39;saddle&#39;, &#39;sandy&#39;, &#34;baker&#39;s&#34;, &#39;semi-&#39;, &#39;semi- sweet&#39;, &#39;very dark&#39;, &#39;dark green&#39;, &#39;dark olive&#39;, &#39;dark sea&#39;, &#39;forest&#39;, &#39;green&#39;, &#39;lawn&#39;, &#39;light sea&#39;, &#39;lime&#39;, &#39;medium sea&#39;, &#39;medium spring&#39;, &#39;mint&#39;, &#39;olive&#39;, &#39;sea&#39;, &#39;spring&#39;, &#39;yellow&#39;, &#39;green yellow&#39;, &#39;hunter&#39;, &#39;hunter green&#39;, &#39;medium forest&#39;, &#39;peach&#39;, &#39;mandarian&#39;, &#39;orange&#39;, &#39;hot&#39;, &#39;indian&#39;, &#39;medium violet&#39;, &#39;misty&#39;, &#39;pale violet&#39;, &#39;violet&#39;, &#39;dusty&#39;, &#39;spicy&#39;, &#39;lavender&#39;, &#39;antique&#39;, &#39;floral&#39;, &#39;ghost&#39;, &#39;navajo&#39;, &#39;old&#39;, &#39;white&#39;, &#39;blanched&#39;, &#39;lemon&#39;, &#39;light goldenrod&#39;, &#39;papaya&#39;, &#39;cool&#39;, &#39;bronze&#39;, &#39;bronze i&#39;, &#39;bright&#39;, &#39;c&#39;, &#39;c s&#39;, &#39;c s s&#39;])</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[22]: dict_keys([&#39;&#39;, &#39;light&#39;, &#39;light slate&#39;, &#39;slate&#39;, &#39;dim&#39;, &#39;dark&#39;, &#39;dark slate&#39;, &#39;very&#39;, &#39;very light&#39;, &#39;free&#39;, &#39;free speech&#39;, &#39;alice&#39;, &#39;blue&#39;, &#39;cadet&#39;, &#39;corn&#39;, &#39;corn flower&#39;, &#39;cornflower&#39;, &#39;deep&#39;, &#39;deep sky&#39;, &#39;dodger&#39;, &#39;light sky&#39;, &#39;light steel&#39;, &#39;medium&#39;, &#39;medium slate&#39;, &#39;midnight&#39;, &#39;navy&#39;, &#39;pale&#39;, &#39;powder&#39;, &#39;royal&#39;, &#39;sky&#39;, &#39;steel&#39;, &#39;true&#39;, &#39;true iris&#39;, &#39;neon&#39;, &#39;new&#39;, &#39;new midnight&#39;, &#39;rich&#39;, &#39;summer&#39;, &#39;iris&#39;, &#39;rosy&#39;, &#39;saddle&#39;, &#39;sandy&#39;, &#34;baker&#39;s&#34;, &#39;semi-&#39;, &#39;semi- sweet&#39;, &#39;very dark&#39;, &#39;dark green&#39;, &#39;dark olive&#39;, &#39;dark sea&#39;, &#39;forest&#39;, &#39;green&#39;, &#39;lawn&#39;, &#39;light sea&#39;, &#39;lime&#39;, &#39;medium sea&#39;, &#39;medium spring&#39;, &#39;mint&#39;, &#39;olive&#39;, &#39;sea&#39;, &#39;spring&#39;, &#39;yellow&#39;, &#39;green yellow&#39;, &#39;hunter&#39;, &#39;hunter green&#39;, &#39;medium forest&#39;, &#39;peach&#39;, &#39;mandarian&#39;, &#39;orange&#39;, &#39;hot&#39;, &#39;indian&#39;, &#39;medium violet&#39;, &#39;misty&#39;, &#39;pale violet&#39;, &#39;violet&#39;, &#39;dusty&#39;, &#39;spicy&#39;, &#39;lavender&#39;, &#39;antique&#39;, &#39;floral&#39;, &#39;ghost&#39;, &#39;navajo&#39;, &#39;old&#39;, &#39;white&#39;, &#39;blanched&#39;, &#39;lemon&#39;, &#39;light goldenrod&#39;, &#39;papaya&#39;, &#39;cool&#39;, &#39;bronze&#39;, &#39;bronze i&#39;, &#39;bright&#39;, &#39;c&#39;, &#39;c s&#39;, &#39;c s s&#39;])</div>"]}}],"execution_count":0},{"cell_type":"code","source":["symbol_extraction_dictionary = {\n    \"length_symbols\":{\n        \"km\",\n        \"hm\",\n        \"dam\",\n        \"m\",\n        \"dm\",\n        \"cm\",\n        \"mm\"\n    },\n\n    \"length_values\":{\n        \"kilometre\",\n        \"hectometre\",\n        \"decametre\",\n        \"metre\",\n        \"decimetre\",\n        \"centimetre\",\n        \"millimetre\",\n        \"kilometer\",\n        \"hectometer\",\n        \"decameter\",\n        \"meter\",\n        \"decimeter\",\n        \"centimeter\",\n        \"millimeter\"\n    },\n\n    \"weight_symbols\":{\n        \"t\",\n        \"kg\",\n        \"hg\",\n        \"dag\",\n        \"g\",\n        \"dg\",\n        \"cg\", \n        \"mg\"\n    },\n\n    \"weight_values\":{\n        \"tonne\",\n        \"kilogram\",\n        \"hectogram\",\n        \"decagram\",\n        \"gram\",\n        \"decigram\",\n        \"centigram\",\n        \"milligram\"\n    },\n\n    \"volume_symbols\":{\n        \"kL\",\n        \"hL\",\n        \"daL\",\n        \"L\",\n        \"dL\",\n        \"cL\",\n        \"mL\"\n    },\n\n    \"volume_values\":{\n        \"kilolitre\",\n        \"hectolitre\",\n        \"decalitre\",\n        \"litre\",\n        \"decilitre\",\n        \"centilitre\",\n        \"millilitre\",\n        \"kiloliter\",\n        \"hectoliter\",\n        \"decaliter\",\n        \"liter\",\n        \"deciliter\",\n        \"centiliter\",\n        \"milliliter\"\n    }\n}\n\nvalue_symbol_conversion = {\n    \"kilometre\": \"km\",\n    \"hectometre\": \"hm\",\n    \"decametre\": \"dam\",\n    \"metre\": \"m\",\n    \"decimetre\": \"dm\",\n    \"centimetre\": \"cm\",\n    \"millimetre\": \"mm\",\n    \"kilometer\": \"km\",\n    \"hectometer\": \"hm\",\n    \"decameter\": \"dam\",\n    \"meter\": \"m\",\n    \"decimeter\": \"dm\",\n    \"centimeter\": \"cm\",\n    \"millimeter\": \"mm\",\n    \"kilometres\": \"km\",\n    \"hectometres\": \"hm\",\n    \"decametres\": \"dam\",\n    \"metres\": \"m\",\n    \"decimetres\": \"dm\",\n    \"centimetres\": \"cm\",\n    \"millimetres\": \"mm\",\n    \"kilometers\": \"km\",\n    \"hectometers\": \"hm\",\n    \"decameters\": \"dam\",\n    \"meters\": \"m\",\n    \"decimeters\": \"dm\",\n    \"centimeters\": \"cm\",\n    \"millimeters\": \"mm\",\n\n    \"tonne\": \"t\",\n    \"kilogram\":\t\"kg\",\n    \"hectogram\": \"hg\",\n    \"decagram\":\t\"dag\",\n    \"gram\":\t\"g\",\n    \"decigram\":\t\"dg\",\n    \"centigram\": \"cg\",\n    \"milligram\": \"mg\",\n    \"tonnes\": \"t\",\n    \"kilograms\": \"kg\",\n    \"hectograms\": \"hg\",\n    \"decagrams\": \"dag\",\n    \"grams\": \"g\",\n    \"decigrams\": \"dg\",\n    \"centigrams\": \"cg\",\n    \"milligrams\": \"mg\",\n\n    \"kilolitre\": \"kL\",\n    \"hectolitre\": \"hL\",\n    \"decalitre\": \"daL\",\n    \"litre\": \"L\",\n    \"decilitre\": \"dL\",\n    \"centilitre\": \"cL\",\n    \"millilitre\": \"mL\",\n    \"kiloliter\": \"kL\",\n    \"hectoliter\": \"hL\",\n    \"decaliter\": \"daL\",\n    \"liter\": \"L\",\n    \"deciliter\": \"dL\",\n    \"centiliter\": \"cL\",\n    \"milliliter\": \"mL\",\n    \"kilolitres\": \"kL\",\n    \"hectolitres\": \"hL\",\n    \"decalitres\": \"daL\",\n    \"litres\": \"L\",\n    \"decilitres\": \"dL\",\n    \"centilitres\": \"cL\",\n    \"millilitres\": \"mL\",\n    \"kiloliters\": \"kL\",\n    \"hectoliters\": \"hL\",\n    \"decaliters\": \"daL\",\n    \"liters\": \"L\",\n    \"deciliters\": \"dL\",\n    \"centiliters\": \"cL\",\n    \"milliliters\": \"mL\",\n    \n    \"dollars\": \"$\",\n    \"Dollars\": \"$\",\n    \"dollar\": \"$\",\n    \"Dollar\": \"$\",\n    \"Euro\": \"€\",\n    \"euro\": \"€\",\n    \"Euros\": \"€\",\n    \"euros\": \"€\",\n    \"Pound\": \"£\",\n    \"pound\": \"£\",\n    \"Pounds\": \"£\",\n    \"pounds\": \"£\",\n    \"Rupee\": \"₹\",\n    \"rupee\": \"₹\",\n    \"Rupees\": \"₹\",\n    \"rupees\": \"₹\"\n}"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d2ced07-c3c0-4c44-b526-94e51509c3b1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def get_preposition_meaning_refined(token, cur_string):\n    left_string = \"\"\n    right_string = \"\"\n    for left_val in token.lefts:\n        left_string += \" \" + left_val.text\n        left_string = get_preposition_meaning_refined(left_val, left_string)\n        \n    for right_val in token.rights:\n        right_string += \" \" + right_val.text\n        right_string = get_preposition_meaning_refined(right_val, right_string)\n        \n    cur_string = left_string + \" \" + cur_string + \" \" + right_string\n    cur_string = cur_string.strip()\n    cur_string = \" \".join(cur_string.split())\n    return cur_string"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"490ebbdb-c9df-411c-9899-d2747152abd8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def unsupervised_feature_extraction_dependency_extraction(sent):\n    ## chunk 1\n    substring_overlap_list = list(filter(lambda x: x in sent, value_symbol_conversion.keys()))\n    substring_overlap_list_sorted = sorted(substring_overlap_list, key=len, reverse=True)\n    for r in substring_overlap_list_sorted:\n        sent = sent.replace(r, value_symbol_conversion[r])\n    is_prev_tok_prep = False\n    doc_num = nlp(sent)\n    doc_num_len = len(doc_num)\n    k = 0\n    category_tok_indices = []\n    word_2_num_dict = defaultdict()\n    while k < doc_num_len:\n        tok_n = doc_num[k]\n        if tok_n.pos_.lower() == 'num':\n            if not tok_n.text.isnumeric():\n                word_num = tok_n.text\n                l = k + 1\n                while l < doc_num_len:\n                    tok_n_next = doc_num[l]\n                    if (tok_n_next.pos_.lower() == 'num' and not tok_n_next.text.isnumeric()):\n                        word_num += \" \" + tok_n_next.text\n                    elif tok_n_next.pos_.lower() == 'cconj':\n                        if l + 1 < doc_num_len and (doc_num[l + 1].pos_.lower() == 'num' and not doc_num[l + 1].text.isnumeric()):\n                            word_num += \" \" + tok_n_next.text\n                        else:\n                            break\n                    else:\n                        break\n                    l += 1\n                try:\n                    word_2_num_dict[word_num] = w2n.word_to_num(word_num)\n                except:\n                    print('*'*10, 'word_num:', word_num, '*'*10)\n                    nlp_word_num = nlp(word_num)\n                    nlp_word_num_len = len(nlp_word_num)\n                    word_num = \"\"\n                    \n                    for index in range(nlp_word_num_len):\n                        word_tok = nlp_word_num[index]\n                        print('@'*5, word_tok.text, word_tok.pos_.lower(), '@'*5)\n                        if word_tok.pos_.lower() == 'num':\n                            word_num += \" \" + word_tok.text\n                            if index == (nlp_word_num_len - 1):\n                                try:\n                                    word_num = word_num.strip()\n                                    print('#'*10, 'word_num:', word_num, '#'*10)\n                                    word_2_num_dict[word_num] = w2n.word_to_num(word_num)\n                                    word_num = \"\"\n                                except:\n                                    print(\"exception\", \"word num:\", word_num)   \n                        else:\n                            try:\n                                word_num = word_num.strip()\n                                print('#'*10, 'word_num:', word_num, '#'*10)\n                                word_2_num_dict[word_num] = w2n.word_to_num(word_num)\n                                word_num = \"\"\n                            except:\n                                print(\"exception\", \"word num:\", word_num)\n\n                k = l - 1\n        k += 1        \n    for key, val in word_2_num_dict.items():\n        sent = sent.replace(key, str(val))\n    \n#     print('sent updated:', sent)\n    \n    category_list = []\n    quality_list = []\n    preposition_list = []\n    preposition_meaning_list = []\n    \n    prefix = \"\"\n    modifier = \"\"\n    category = \"\"\n    doc = nlp(sent)\n    doc_len = len(doc)\n    i = 0\n    while i < doc_len:\n        tok = doc[i]        \n        ## chunk 3: check if token is a modifier or not\n        if tok.dep_.endswith(\"mod\") == True and (tok.dep_.lower() != 'nummod' or (not is_prev_tok_prep and (not preposition_meaning_list or tok.text not in preposition_meaning_list[-1]))):\n            modifier = prefix + \" \" + tok.text\n            j = i + 1\n            while j < doc_len:\n                tok_next = doc[j]\n                if tok_next.dep_.endswith(\"mod\"):\n                    modifier += \" \" + tok_next.text\n                    j += 1\n                else:\n                    break\n            i = j - 1\n            modifier = modifier.strip()\n            modifier = \" \".join(modifier.split())\n            quality_list.append(modifier)\n            prefix = \"\"\n            modifier = \"\"\n            category = \"\"\n            is_prev_tok_prep = False\n\n        ## chunk 2: check if token is a noun or not    \n        elif (tok.pos_.lower() == 'propn' or tok.pos_.lower() == 'noun') and (tok.dep_.lower() != 'pobj'):\n            category = prefix + \" \" + tok.text\n            j = i + 1\n            while j < doc_len:\n                tok_next = doc[j]\n                if (tok_next.pos_.lower() == 'propn' or tok_next.pos_.lower() == 'noun') and (tok.dep_.lower() != 'pobj'):\n                    category += \" \" + tok_next.text\n                    j += 1\n                else:\n                    break\n            \n            category_tok_indices.append((i, j))\n            i = j - 1\n            category = category.strip()\n            category = \" \".join(category.split())\n            category_list.append(category)\n            prefix = \"\"\n            modifier = \"\"\n            category = \"\"\n            is_prev_tok_prep = False\n\n        \n        ## chunk 4: check if token is a coumpuund word or not\n        elif tok.dep_ != \"punct\" and tok.dep_.lower() == 'compound':\n            prefix += \" \" + tok.text\n            j = i + 1\n            while j < doc_len:\n                tok_next = doc[j]\n                if tok_next.dep_.lower() == 'compound':\n                    prefix += \" \" + tok_next.text\n                    j += 1\n                else:\n                    break\n            is_prev_tok_prep = False\n                    \n        elif tok.dep_ == 'prep':\n            prep_string = \"\"\n            preposition_list.append(tok.text)\n            preposition_meaning_list.append(get_preposition_meaning_refined(tok, prep_string))\n            is_prev_tok_prep = True\n        \n        else:\n            is_prev_tok_prep = False\n        \n        i += 1\n\n    category_feature_relation = []\n    for cat_index, cat_tuple in enumerate(category_tok_indices):\n        rel_found = False\n        for tok_index in range(cat_tuple[0], cat_tuple[1]):\n            tok = doc[tok_index]\n            for child in tok.children:\n                for quality in quality_list:\n                    if child.text in quality:\n                        category_feature_relation.append(category_list[cat_index] + \":\" + quality)\n                        rel_found = True\n                        break\n                if rel_found:\n                    break\n            if rel_found:\n                break\n            \n    \n    return quality_list, category_list, preposition_list, preposition_meaning_list, category_feature_relation"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5798b6de-7a4f-4eb2-950c-460baeb13311"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def unsupervised_feature_extraction_dependency_extraction_fashion(sent):\n    ## chunk 1\n    substring_overlap_list = list(filter(lambda x: x in sent, value_symbol_conversion.keys()))\n    substring_overlap_list_sorted = sorted(substring_overlap_list, key=len, reverse=True)\n    for r in substring_overlap_list_sorted:\n        sent = sent.replace(r, value_symbol_conversion[r])\n    is_prev_tok_prep = False\n    doc_num = nlp(sent)\n    doc_num_len = len(doc_num)\n    k = 0\n    category_tok_indices = []\n    word_2_num_dict = defaultdict()\n    while k < doc_num_len:\n        tok_n = doc_num[k]\n        if tok_n.pos_.lower() == 'num':\n            if not tok_n.text.isnumeric():\n                word_num = tok_n.text\n                l = k + 1\n                while l < doc_num_len:\n                    tok_n_next = doc_num[l]\n                    if (tok_n_next.pos_.lower() == 'num' and not tok_n_next.text.isnumeric()):\n                        word_num += \" \" + tok_n_next.text\n                    elif tok_n_next.pos_.lower() == 'cconj':\n                        if l + 1 < doc_num_len and (doc_num[l + 1].pos_.lower() == 'num' and not doc_num[l + 1].text.isnumeric()):\n                            word_num += \" \" + tok_n_next.text\n                        else:\n                            break\n                    else:\n                        break\n                    l += 1\n                try:\n                    word_2_num_dict[word_num] = w2n.word_to_num(word_num)\n                except:\n                    print('*'*10, 'word_num:', word_num, '*'*10)\n                    nlp_word_num = nlp(word_num)\n                    nlp_word_num_len = len(nlp_word_num)\n                    word_num = \"\"\n                    \n                    for index in range(nlp_word_num_len):\n                        word_tok = nlp_word_num[index]\n                        print('@'*5, word_tok.text, word_tok.pos_.lower(), '@'*5)\n                        if word_tok.pos_.lower() == 'num':\n                            word_num += \" \" + word_tok.text\n                            if index == (nlp_word_num_len - 1):\n                                try:\n                                    word_num = word_num.strip()\n                                    print('#'*10, 'word_num:', word_num, '#'*10)\n                                    word_2_num_dict[word_num] = w2n.word_to_num(word_num)\n                                    word_num = \"\"\n                                except:\n                                    print(\"exception\", \"word num:\", word_num)   \n                        else:\n                            try:\n                                word_num = word_num.strip()\n                                print('#'*10, 'word_num:', word_num, '#'*10)\n                                word_2_num_dict[word_num] = w2n.word_to_num(word_num)\n                                word_num = \"\"\n                            except:\n                                print(\"exception\", \"word num:\", word_num)\n\n                k = l - 1\n        k += 1        \n    for key, val in word_2_num_dict.items():\n        sent = sent.replace(key, str(val))\n    \n#     print('sent updated:', sent)\n    \n    category_list = []\n    quality_list = []\n    preposition_list = []\n    preposition_meaning_list = []\n    \n    prefix = \"\"\n    modifier = \"\"\n    category = \"\"\n    doc = nlp(sent)\n    doc_len = len(doc)\n    i = 0\n    while i < doc_len:\n        tok = doc[i]        \n        ## chunk 3: check if token is a modifier or not\n        if tok.dep_.endswith(\"mod\") == True and (tok.dep_.lower() != 'nummod' or (not is_prev_tok_prep and (not preposition_meaning_list or tok.text not in preposition_meaning_list[-1]))):\n            modifier = prefix + \" \" + tok.text\n            j = i + 1\n            while j < doc_len:\n                tok_next = doc[j]\n                if tok_next.dep_.endswith(\"mod\"):\n                    modifier += \" \" + tok_next.text\n                    j += 1\n                else:\n                    break\n            i = j - 1\n            modifier = modifier.strip()\n            modifier = \" \".join(modifier.split())\n            quality_list.append(modifier)\n            prefix = \"\"\n            modifier = \"\"\n            category = \"\"\n            is_prev_tok_prep = False\n            \n        ## chunk 4: check if token is a coumpuund word or not\n        elif tok.dep_ != \"punct\" and tok.dep_.lower() == 'compound':\n            prefix = tok.text\n            j = i + 1\n            while j < doc_len:\n                tok_next = doc[j]\n                if tok_next.dep_.lower() == 'compound':\n                    prefix += \" \" + tok_next.text\n                    j += 1\n                else:\n                    break\n            i = j - 1\n            quality_list.append(prefix)\n            prefix = \"\"\n            modifier = \"\"\n            category = \"\"\n            is_prev_tok_prep = False\n\n        ## chunk 2: check if token is a noun or not    \n        elif (tok.pos_.lower() == 'propn' or tok.pos_.lower() == 'noun') and (tok.dep_.lower() != 'pobj'):\n            category = prefix + \" \" + tok.text\n            j = i + 1\n            while j < doc_len:\n                tok_next = doc[j]\n                if (tok_next.pos_.lower() == 'propn' or tok_next.pos_.lower() == 'noun') and (tok.dep_.lower() != 'pobj'):\n                    category += \" \" + tok_next.text\n                    j += 1\n                else:\n                    break\n            \n            category_tok_indices.append((i, j))\n            i = j - 1\n            category = category.strip()\n            category = \" \".join(category.split())\n            category_list.append(category)\n            prefix = \"\"\n            modifier = \"\"\n            category = \"\"\n            is_prev_tok_prep = False\n\n                    \n        elif tok.dep_ == 'prep':\n            prep_string = \"\"\n            preposition_list.append(tok.text)\n            preposition_meaning_list.append(get_preposition_meaning_refined(tok, prep_string))\n            is_prev_tok_prep = True\n        \n        else:\n            is_prev_tok_prep = False\n        \n        i += 1\n\n    category_feature_relation = []\n    for cat_index, cat_tuple in enumerate(category_tok_indices):\n        quality_set = set()\n        for tok_index in range(cat_tuple[0], cat_tuple[1]):\n            tok = doc[tok_index]\n            for child in tok.children:\n                for quality in quality_list:\n                    if child.text in quality and quality not in quality_set:\n                        category_feature_relation.append(category_list[cat_index] + \":\" + quality)\n                        quality_set.add(quality)\n                        break\n            \n    \n    return quality_list, category_list, preposition_list, preposition_meaning_list, category_feature_relation"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"51f21f9a-bd76-47c4-8499-83ee1ab41373"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["unsupervised_feature_extraction_dependency_extraction(\"Android Phone 6GB RAM below 7 inches\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e98a210b-c85a-47f0-b796-bf0f2803458a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[27]: ([&#39;6&#39;], [&#39;Android Phone&#39;, &#39;GB RAM&#39;], [&#39;below&#39;], [&#39;7 inches&#39;], [&#39;GB RAM:6&#39;])</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[27]: ([&#39;6&#39;], [&#39;Android Phone&#39;, &#39;GB RAM&#39;], [&#39;below&#39;], [&#39;7 inches&#39;], [&#39;GB RAM:6&#39;])</div>"]}}],"execution_count":0},{"cell_type":"code","source":["unsupervised_feature_extraction_dependency_extraction_fashion(\"Android Phone 6GB RAM below 7 inches\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fbf0b16a-8c8b-41a8-ad21-831d01b33195"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[28]: ([&#39;Android&#39;, &#39;6&#39;, &#39;GB&#39;],\n [&#39;Phone&#39;, &#39;RAM&#39;],\n [&#39;below&#39;],\n [&#39;7 inches&#39;],\n [&#39;Phone:Android&#39;, &#39;RAM:6&#39;, &#39;RAM:GB&#39;])</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[28]: ([&#39;Android&#39;, &#39;6&#39;, &#39;GB&#39;],\n [&#39;Phone&#39;, &#39;RAM&#39;],\n [&#39;below&#39;],\n [&#39;7 inches&#39;],\n [&#39;Phone:Android&#39;, &#39;RAM:6&#39;, &#39;RAM:GB&#39;])</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# string = \"Android Phone 6GB RAM below 7 inches\"\n# string = \"Off Shoulder Dress\"\nstring = \"red sheath dress\"\ndoc = nlp(string)\nfor tok in doc:\n    print(tok.text, tok.dep_, tok.pos_, tok.lemma_)\n    for child in tok.children:\n        print('child:', child, 'type:', type(child))\n    for child in tok.rights:\n        print('rights:', child, 'type:', type(child))\n    for child in tok.lefts:\n        print('lefts:', child, 'type:', type(child))\nfor ent in doc.ents:\n    print(ent.text, ent.start_char, ent.end_char, ent.label_)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"be3cddb9-0c6b-44c2-8c1a-2d681c5a7ed6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">red amod ADJ red\nsheath compound NOUN sheath\ndress ROOT NOUN dress\nchild: red type: &lt;class &#39;spacy.tokens.token.Token&#39;&gt;\nchild: sheath type: &lt;class &#39;spacy.tokens.token.Token&#39;&gt;\nlefts: red type: &lt;class &#39;spacy.tokens.token.Token&#39;&gt;\nlefts: sheath type: &lt;class &#39;spacy.tokens.token.Token&#39;&gt;\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">red amod ADJ red\nsheath compound NOUN sheath\ndress ROOT NOUN dress\nchild: red type: &lt;class &#39;spacy.tokens.token.Token&#39;&gt;\nchild: sheath type: &lt;class &#39;spacy.tokens.token.Token&#39;&gt;\nlefts: red type: &lt;class &#39;spacy.tokens.token.Token&#39;&gt;\nlefts: sheath type: &lt;class &#39;spacy.tokens.token.Token&#39;&gt;\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Custom training of NER - But it destroying other pretained weights"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5bfbfc37-8ac5-4221-b95f-bfd4e202086a"}}},{"cell_type":"code","source":["nlp_update = spacy.load('en_core_web_lg')\n\nstring = \"red dress less than 20000$\"\ndoc = nlp_update(string)\nfor tok in doc:\n    print(tok.text, tok.dep_, tok.pos_, tok.lemma_)\n    for child in tok.children:\n        print('child:', child, 'type:', type(child))\n    for child in tok.rights:\n        print('rights:', child, 'type:', type(child))\n    for child in tok.lefts:\n        print('lefts:', child, 'type:', type(child))\nfor ent in doc.ents:\n    print(ent.text, ent.start_char, ent.end_char, ent.label_)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4a742d79-b9e5-4e76-a346-84d42a17141b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">OSError</span>                                   Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3436982846460313&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>nlp_update <span class=\"ansi-blue-fg\">=</span> spacy<span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;en_core_web_lg&#39;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> string <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;red dress less than 20000$&#34;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> doc <span class=\"ansi-blue-fg\">=</span> nlp_update<span class=\"ansi-blue-fg\">(</span>string<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> <span class=\"ansi-green-fg\">for</span> tok <span class=\"ansi-green-fg\">in</span> doc<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/spacy/__init__.py</span> in <span class=\"ansi-cyan-fg\">load</span><span class=\"ansi-blue-fg\">(name, **overrides)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     28</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     29</span> def load(\n<span class=\"ansi-green-fg\">---&gt; 30</span><span class=\"ansi-red-fg\">     </span>name<span class=\"ansi-blue-fg\">:</span> Union<span class=\"ansi-blue-fg\">[</span>str<span class=\"ansi-blue-fg\">,</span> Path<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     31</span>     <span class=\"ansi-blue-fg\">*</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     32</span>     vocab<span class=\"ansi-blue-fg\">:</span> Union<span class=\"ansi-blue-fg\">[</span>Vocab<span class=\"ansi-blue-fg\">,</span> bool<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">True</span><span class=\"ansi-blue-fg\">,</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/spacy/util.py</span> in <span class=\"ansi-cyan-fg\">load_model</span><span class=\"ansi-blue-fg\">(name, **overrides)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    161</span>     dictionary). Will raise an error if user or spaCy attempts to add to dict.\n<span class=\"ansi-green-intense-fg ansi-bold\">    162</span>     &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 163</span><span class=\"ansi-red-fg\"> </span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    164</span>     <span class=\"ansi-green-fg\">def</span> __init__<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">,</span> error<span class=\"ansi-blue-fg\">:</span> str <span class=\"ansi-blue-fg\">=</span> Errors<span class=\"ansi-blue-fg\">.</span>E095<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">-&gt;</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    165</span>         &#34;&#34;&#34;Initialize the frozen dict. Can be initialized with pre-defined\n\n<span class=\"ansi-red-fg\">OSError</span>: [E049] Can&#39;t find spaCy data directory: &#39;None&#39;. Check your installation and permissions, or use spacy.util.set_data_path to customise the location if necessary.</div>","errorSummary":"<span class=\"ansi-red-fg\">OSError</span>: [E049] Can&#39;t find spaCy data directory: &#39;None&#39;. Check your installation and permissions, or use spacy.util.set_data_path to customise the location if necessary.","metadata":{},"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">OSError</span>                                   Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3436982846460313&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>nlp_update <span class=\"ansi-blue-fg\">=</span> spacy<span class=\"ansi-blue-fg\">.</span>load<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;en_core_web_lg&#39;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> string <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">&#34;red dress less than 20000$&#34;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> doc <span class=\"ansi-blue-fg\">=</span> nlp_update<span class=\"ansi-blue-fg\">(</span>string<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> <span class=\"ansi-green-fg\">for</span> tok <span class=\"ansi-green-fg\">in</span> doc<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/spacy/__init__.py</span> in <span class=\"ansi-cyan-fg\">load</span><span class=\"ansi-blue-fg\">(name, **overrides)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     28</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     29</span> def load(\n<span class=\"ansi-green-fg\">---&gt; 30</span><span class=\"ansi-red-fg\">     </span>name<span class=\"ansi-blue-fg\">:</span> Union<span class=\"ansi-blue-fg\">[</span>str<span class=\"ansi-blue-fg\">,</span> Path<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     31</span>     <span class=\"ansi-blue-fg\">*</span><span class=\"ansi-blue-fg\">,</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     32</span>     vocab<span class=\"ansi-blue-fg\">:</span> Union<span class=\"ansi-blue-fg\">[</span>Vocab<span class=\"ansi-blue-fg\">,</span> bool<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">True</span><span class=\"ansi-blue-fg\">,</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.7/site-packages/spacy/util.py</span> in <span class=\"ansi-cyan-fg\">load_model</span><span class=\"ansi-blue-fg\">(name, **overrides)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    161</span>     dictionary). Will raise an error if user or spaCy attempts to add to dict.\n<span class=\"ansi-green-intense-fg ansi-bold\">    162</span>     &#34;&#34;&#34;\n<span class=\"ansi-green-fg\">--&gt; 163</span><span class=\"ansi-red-fg\"> </span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    164</span>     <span class=\"ansi-green-fg\">def</span> __init__<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">,</span> error<span class=\"ansi-blue-fg\">:</span> str <span class=\"ansi-blue-fg\">=</span> Errors<span class=\"ansi-blue-fg\">.</span>E095<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kwargs<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-blue-fg\">-&gt;</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    165</span>         &#34;&#34;&#34;Initialize the frozen dict. Can be initialized with pre-defined\n\n<span class=\"ansi-red-fg\">OSError</span>: [E049] Can&#39;t find spaCy data directory: &#39;None&#39;. Check your installation and permissions, or use spacy.util.set_data_path to customise the location if necessary.</div>"]}}],"execution_count":0},{"cell_type":"code","source":["unsupervised_feature_extraction_dependency_extraction_fashion(\"Off Shoulder Dress\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4165de3b-cd67-4a21-be6f-1d8d55ac983d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[32]: ([], [&#39;Off Shoulder Dress&#39;], [], [], [])</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[32]: ([], [&#39;Off Shoulder Dress&#39;], [], [], [])</div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d3c6b8df-315e-4fec-a8b6-9bfdd45dfbb3"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"search_tagger","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":3548166042699276}},"nbformat":4,"nbformat_minor":0}
