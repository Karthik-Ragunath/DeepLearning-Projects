{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd34ab5-b1de-4d81-b3a9-60746ff6d91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57483d18-d873-4c33-90fa-374dc949f995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedecd57-22d6-4079-a225-7c75a9d91b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bert-tensorflow==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df409f9-b2d1-406a-a45c-05827e9b0857",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c94bc8a-608a-4e3e-871f-9f87a11116da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eef5fad-7765-43cf-8359-d237b8ac5a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import logging\n",
    "# logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf6c330-a7c7-4680-b324-d37184acd976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee85b7b0-ab9a-404c-99b1-f3f7dcdabdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import bert\n",
    "# from bert import optimization\n",
    "# from bert import tokenization\n",
    "import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adc41523-2cdd-43f9-8d8c-adfb553afdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ca81fd4-d4c4-4f7d-b326-59be531db134",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2'\n",
    "bert_layer = hub.KerasLayer(module_url, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7437abec-51ed-4c45-a4c4-676555716906",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json(\"github_prediction_data/embold_train.json\").reset_index(drop=True)\n",
    "test = pd.read_json(\"github_prediction_data/embold_test.json\").reset_index(drop=True)\n",
    "\n",
    "train = train[:1000]\n",
    "test = test[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30e7c31f-2074-4a98-b462-3acccce024c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28b01b58-de62-4b3b-a9c3-e6027a8b0601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a63cf71-5af8-4701-9756-7c3e83f0557c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'body', 'label'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce219e50-3dd2-4ca8-bffe-08d388bd7bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Review'] = (train['title'].map(str) +' '+ train['body']).apply(lambda row: row.strip())\n",
    "test['Review'] = (test['title'].map(str) +' '+ test['body']).apply(lambda row: row.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "740356de-c171-4836-86d1-d798cbf27780",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35328caf-a666-4f41-b987-d7f3484207c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for index, text in enumerate(texts):\n",
    "        text = tokenizer.tokenize(text)\n",
    "        if index == 0:\n",
    "            print(text)\n",
    "        text = text[:max_len-2]\n",
    "        if index == 0:\n",
    "            print('text truncated:', text)\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "    \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a54122e0-bc05-4564-87fa-072204a10118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/questions-and-answers/86510\n",
    "# sequence outout - [batch_size, max_seq_length, 768]\n",
    "# pooled output - [batch_size, 768] \n",
    "\n",
    "'''\n",
    "the first token of output sequence is from the first of input ，i e. [CLS]. \n",
    "the [CLS] is regarded as the represition of the whole input sequence. u can read the original paper to understand it better.\n",
    "https://stackoverflow.com/questions/63377198/what-is-the-difference-between-pulled-output-and-sequence-output-in-bert-layer\n",
    "https://stackoverflow.com/questions/60293712/how-is-bert-layer-sequence-output-used\n",
    "'''\n",
    "\n",
    "def build_model(bert_layer, max_len=512):\n",
    "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    net = tf.keras.layers.Dense(64, activation='relu')(clf_output)\n",
    "    net = tf.keras.layers.Dropout(0.2)(net)\n",
    "    net = tf.keras.layers.Dense(32, activation='relu')(net)\n",
    "    net = tf.keras.layers.Dropout(0.2)(net)\n",
    "    out = tf.keras.layers.Dense(3, activation='softmax')(net)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
    "    model.compile(tf.keras.optimizers.Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0238aebf-446b-478d-8fcb-8a0846c792a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_pooled_output(bert_layer, max_len=512):\n",
    "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    net = tf.keras.layers.Dense(64, activation='relu')(pooled_output)\n",
    "    net = tf.keras.layers.Dropout(0.2)(net)\n",
    "    net = tf.keras.layers.Dense(32, activation='relu')(net)\n",
    "    net = tf.keras.layers.Dropout(0.2)(net)\n",
    "    out = tf.keras.layers.Dense(3, activation='softmax')(net)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
    "    model.compile(tf.keras.optimizers.Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ffcab7d-0877-489f-89b3-603b86a77fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0fc9ca9-7f85-49a5-ae98-eae8e49d43a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['y', '-', 'zoom', 'piano', 'roll', 'a', 'y', '-', 'zoom', 'on', 'the', 'piano', 'roll', 'would', 'be', 'useful', '.']\n",
      "text truncated: ['y', '-', 'zoom', 'piano', 'roll', 'a', 'y', '-', 'zoom', 'on', 'the', 'piano', 'roll', 'would', 'be', 'useful', '.']\n",
      "['con', '##fi', '##g', 'question', 'path', '-', 'specific', 'environment', 'variables', 'issue', 'description', 'or', 'question', '\\\\', 'r', '\\\\', 'r', 'hey', '@', 'arte', '##mg', '##ovo', '##rov', '!', 'thanks', 'for', 'your', 'previous', 'help', 'with', 'the', 'module', 'alias', '##ing', 'in', 'my', 'le', '##rna', 'rep', '##o', '.', 'i', \"'\", 'm', 'still', 'trying', 'to', 'work', 'out', 'more', 'of', 'the', 'kin', '##ks', '.', '\\\\', 'r', '\\\\', 'r', 'is', 'there', 'any', 'way', 'to', 'set', 'up', 'the', 'en', '##v', 'variables', 'before', 'tests', 'in', 'each', 'file', 'are', 'run', '?', 'the', 'setup', 'requires', ':', '\\\\', 'r', 'tests', 'in', 'packages', '/', 'module', '-', 'a', 'need', 'my', '_', 'en', '##v', 'to', 'be', 'test', '\\\\', 'r', 'tests', 'in', 'packages', '/', 'module', '-', 'b', 'need', 'my', '_', 'en', '##v', 'to', 'be', 'testing', '.', '\\\\', 'r', '\\\\', 'r', 'any', 'ideas', '?', '\\\\', 'r', '\\\\', 'r', 'i', 'can', \"'\", 't', 'seem', 'to', 'find', 'the', 'function', 'that', 'would', 'be', 'evaluated', 'before', 'each', 'file', 'is', 'run', 'in', 'the', 'doc', '##s', 'to', 'do', 'something', 'like', ':', '\\\\', 'r', '\\\\', 'r', 'j', '##s', '\\\\', 'r', 'before', '##test', '##sin', '##fi', '##ler', '##un', 'path', '{', '\\\\', 'r', 'process', '.', 'en', '##v', '.', 'my', '_', 'en', '##v', '=', 'path', '.', 'includes', '\\\\', 'packages', '/', 'module', '-', 'b', '\\\\', '?', \"'\", 'testing', \"'\", ':', \"'\", 'test', \"'\", '\\\\', 'r', '}', '\\\\', 'r', '\\\\', 'r', '\\\\', 'r', 'thanks', 'in', 'advance', '!', '\\\\', 'r', '\\\\', 'r', '\\\\', 'r', 'code', 'editor', 'or', 'id', '##e', 'name', 'and', 'version', '\\\\', 'r', '\\\\', 'r', 'visual', 'studio', 'code', 'v', '##1', '.', '21', '.', '1', '\\\\', 'r', '\\\\', 'r', 'os', 'name', 'and', 'version', '\\\\', 'r', '\\\\', 'r', 'os', '##x', '10', '.', '13', '.', '4', '\\\\', 'r']\n",
      "text truncated: ['con', '##fi', '##g', 'question', 'path', '-', 'specific', 'environment', 'variables', 'issue', 'description', 'or', 'question', '\\\\', 'r', '\\\\', 'r', 'hey', '@', 'arte', '##mg', '##ovo', '##rov', '!', 'thanks', 'for', 'your', 'previous', 'help', 'with', 'the', 'module', 'alias', '##ing', 'in', 'my', 'le', '##rna', 'rep', '##o', '.', 'i', \"'\", 'm', 'still', 'trying', 'to', 'work', 'out', 'more', 'of', 'the', 'kin', '##ks', '.', '\\\\', 'r', '\\\\', 'r', 'is', 'there', 'any', 'way', 'to', 'set', 'up', 'the', 'en', '##v', 'variables', 'before', 'tests', 'in', 'each', 'file', 'are', 'run', '?', 'the', 'setup', 'requires', ':', '\\\\', 'r', 'tests', 'in', 'packages', '/', 'module', '-', 'a', 'need', 'my', '_', 'en', '##v', 'to', 'be', 'test', '\\\\', 'r', 'tests', 'in', 'packages', '/', 'module', '-', 'b', 'need', 'my', '_', 'en', '##v', 'to', 'be', 'testing', '.', '\\\\', 'r', '\\\\', 'r', 'any', 'ideas', '?', '\\\\', 'r', '\\\\', 'r', 'i', 'can', \"'\", 't', 'seem', 'to', 'find', 'the', 'function', 'that', 'would', 'be', 'evaluated', 'before', 'each', 'file', 'is', 'run', 'in', 'the']\n"
     ]
    }
   ],
   "source": [
    "max_len = 150\n",
    "train_input = bert_encode(train.Review.values, tokenizer, max_len=max_len)\n",
    "test_input = bert_encode(test.Review.values, tokenizer, max_len=max_len)\n",
    "train_labels = to_categorical(train.label.values, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05714d33-4fe2-4543-bdf6-077fca46b99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_2 (Sli (None, 768)          0           keras_layer[2][1]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           49216       tf.__operators__.getitem_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 32)           2080        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 3)            99          dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 109,533,636\n",
      "Trainable params: 109,533,635\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(bert_layer, max_len=max_len)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3642b023-4c1e-419f-bd22-2069d640fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('bert_multi_class_classifier_github.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ccee180-3667-4d7e-8f1c-ed505a6ec3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25/25 [==============================] - 38s 1s/step - loss: 0.9491 - accuracy: 0.5425 - val_loss: 0.8671 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62500, saving model to bert_multi_class_classifier_github.h5\n",
      "Epoch 2/3\n",
      "25/25 [==============================] - 25s 1s/step - loss: 0.8131 - accuracy: 0.6325 - val_loss: 0.7520 - val_accuracy: 0.7100\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.62500 to 0.71000, saving model to bert_multi_class_classifier_github.h5\n",
      "Epoch 3/3\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.7090 - accuracy: 0.7063 - val_loss: 0.6847 - val_accuracy: 0.7050\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.71000\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(\n",
    "    train_input, train_labels, \n",
    "    validation_split=0.2,\n",
    "    epochs=3,\n",
    "    callbacks=[checkpoint, earlystopping],\n",
    "    batch_size=32,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adbbc73-39bd-4b7a-8877-2a68ac053476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31dfcc9d-5c45-483f-985c-3a0935a3624e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 150)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           49216       keras_layer[3][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 32)           2080        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 3)            99          dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 109,533,636\n",
      "Trainable params: 109,533,635\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_pooled = build_model_pooled_output(bert_layer, max_len=max_len)\n",
    "model_pooled.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8359abd0-2acb-4fa5-aa43-7669b0797911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25/25 [==============================] - 31s 1s/step - loss: 1.0136 - accuracy: 0.4550 - val_loss: 0.8580 - val_accuracy: 0.7050\n",
      "\n",
      "Epoch 00001: val_accuracy did not improve from 0.71000\n",
      "Epoch 2/3\n",
      "25/25 [==============================] - 25s 1s/step - loss: 0.8684 - accuracy: 0.6112 - val_loss: 0.7634 - val_accuracy: 0.7550\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.71000 to 0.75500, saving model to bert_multi_class_classifier_github.h5\n",
      "Epoch 3/3\n",
      "25/25 [==============================] - 25s 1s/step - loss: 0.7081 - accuracy: 0.7462 - val_loss: 0.7072 - val_accuracy: 0.7350\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.75500\n"
     ]
    }
   ],
   "source": [
    "train_history = model_pooled.fit(\n",
    "    train_input, train_labels, \n",
    "    validation_split=0.2,\n",
    "    epochs=3,\n",
    "    callbacks=[checkpoint, earlystopping],\n",
    "    batch_size=32,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "057a0780-f94b-4943-a495-b49fe9cd446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# works better with pooled output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6fc16c-f4ee-4355-8738-9735dc519ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2770711-15a9-4369-a07b-375746779e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc15e894-6bc6-43bf-9ac5-71136c21151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[['123']]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a5c1efa-de35-479a-b5b3-ba6fc2882fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5761be6d-3713-4953-8201-ae3c274e2b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['123']], dtype='<U3')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68079ede-3872-41b0-a265-0175155d38ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d74497-3a7d-42e5-bfbc-1deb581ba26c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7865a0-0177-4539-91e3-5956eced7880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af9cc797-a2e0-4fd4-82fe-698a27b39ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f59f3552-3695-42a6-8321-fb8591c3716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('kohls_data/kohlscatalog-poc-master.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a291240e-89d5-4198-93f8-9a5366d7eff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['productId', 'title', 'Category(Fashion, Beauty, Home)', 'description',\n",
       "       'url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6795f9f-1a15-4556-a462-ac5deb7474c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16405b84-838d-4b43-908e-6ab1a37a54b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aed8da1-2c58-41d9-b81b-08caffc1f490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Model, Input\n",
    " \n",
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, max_length, seed_text, n_words):\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # pre-pad sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "    return in_text\n",
    "\n",
    "# source text\n",
    "data = \"\"\" Jack and Jill went up the hill\\n\n",
    "\t\tTo fetch a pail of water\\n\n",
    "\t\tJack fell down and broke his crown\\n\n",
    "\t\tAnd Jill came tumbling after\\n \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "101ea219-7ea5-4f15-8b0e-ff6e4abc9043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, max_length, seed_text, n_words):\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # pre-pad sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat_preds = model.predict(encoded, verbose=0)\n",
    "        yhat = np.argmax(yhat_preds,axis=-1)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec32d4a5-1415-4c49-8051-03379e09e810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8683dbb-76d6-43e6-b9b1-378ae59bb31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = tokenizer.texts_to_sequences([data])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c575804-7f6d-4d66-9d6a-b9f6e48b9de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 2,\n",
       " 14,\n",
       " 15,\n",
       " 1,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 1,\n",
       " 3,\n",
       " 19,\n",
       " 20,\n",
       " 21]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b40b2188-d132-4df4-8f7c-55dda600b949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2,\n",
       "  1,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  2,\n",
       "  14,\n",
       "  15,\n",
       "  1,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  1,\n",
       "  3,\n",
       "  19,\n",
       "  20,\n",
       "  21]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfee5424-d5c3-4f8d-bbd1-75b2662c2130",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = list()\n",
    "for i in range(2, len(encoded)):\n",
    "    sequence = encoded[i-2:i+1]\n",
    "    sequences.append(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10db3110-3272-4784-b809-79aa76c0b498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 1, 3],\n",
       " [1, 3, 4],\n",
       " [3, 4, 5],\n",
       " [4, 5, 6],\n",
       " [5, 6, 7],\n",
       " [6, 7, 8],\n",
       " [7, 8, 9],\n",
       " [8, 9, 10],\n",
       " [9, 10, 11],\n",
       " [10, 11, 12],\n",
       " [11, 12, 13],\n",
       " [12, 13, 2],\n",
       " [13, 2, 14],\n",
       " [2, 14, 15],\n",
       " [14, 15, 1],\n",
       " [15, 1, 16],\n",
       " [1, 16, 17],\n",
       " [16, 17, 18],\n",
       " [17, 18, 1],\n",
       " [18, 1, 3],\n",
       " [1, 3, 19],\n",
       " [3, 19, 20],\n",
       " [19, 20, 21]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f49028e-b988-4b82-b39f-79cfdcbc1bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = max([len(seq) for seq in sequences])\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dece6719-f425-44ad-a539-243c47c5df3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74506043-e0a2-417a-8786-eab82916f806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  1,  3],\n",
       "       [ 1,  3,  4],\n",
       "       [ 3,  4,  5],\n",
       "       [ 4,  5,  6],\n",
       "       [ 5,  6,  7],\n",
       "       [ 6,  7,  8],\n",
       "       [ 7,  8,  9],\n",
       "       [ 8,  9, 10],\n",
       "       [ 9, 10, 11],\n",
       "       [10, 11, 12],\n",
       "       [11, 12, 13],\n",
       "       [12, 13,  2],\n",
       "       [13,  2, 14],\n",
       "       [ 2, 14, 15],\n",
       "       [14, 15,  1],\n",
       "       [15,  1, 16],\n",
       "       [ 1, 16, 17],\n",
       "       [16, 17, 18],\n",
       "       [17, 18,  1],\n",
       "       [18,  1,  3],\n",
       "       [ 1,  3, 19],\n",
       "       [ 3, 19, 20],\n",
       "       [19, 20, 21]], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "701f267d-e18a-4761-95ae-4745accb1985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  1,  3],\n",
       "       [ 1,  3,  4],\n",
       "       [ 3,  4,  5],\n",
       "       [ 4,  5,  6],\n",
       "       [ 5,  6,  7],\n",
       "       [ 6,  7,  8],\n",
       "       [ 7,  8,  9],\n",
       "       [ 8,  9, 10],\n",
       "       [ 9, 10, 11],\n",
       "       [10, 11, 12],\n",
       "       [11, 12, 13],\n",
       "       [12, 13,  2],\n",
       "       [13,  2, 14],\n",
       "       [ 2, 14, 15],\n",
       "       [14, 15,  1],\n",
       "       [15,  1, 16],\n",
       "       [ 1, 16, 17],\n",
       "       [16, 17, 18],\n",
       "       [17, 18,  1],\n",
       "       [18,  1,  3],\n",
       "       [ 1,  3, 19],\n",
       "       [ 3, 19, 20],\n",
       "       [19, 20, 21]], dtype=int32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = array(sequences)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cf0990c-4a59-42cd-9a83-bebb017dcdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 22\n",
      "Total Sequences: 23\n",
      "Max Sequence Length: 3\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/15\n",
      "1/1 [==============================] - 16s 16s/step - loss: 3.0905 - accuracy: 0.0000e+00 - val_loss: 3.0956 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/15\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.0890 - accuracy: 0.0556 - val_loss: 3.0971 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/15\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.0879 - accuracy: 0.1667 - val_loss: 3.0987 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/15\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.0869 - accuracy: 0.2222 - val_loss: 3.1002 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/15\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.0856 - accuracy: 0.2778 - val_loss: 3.1018 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/15\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.0844 - accuracy: 0.2222 - val_loss: 3.1034 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/15\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.0832 - accuracy: 0.1667 - val_loss: 3.1050 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/15\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.0817 - accuracy: 0.2778 - val_loss: 3.1066 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/15\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.0803 - accuracy: 0.1667 - val_loss: 3.1083 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/15\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.0792 - accuracy: 0.2778 - val_loss: 3.1100 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/15\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.0776 - accuracy: 0.1667 - val_loss: 3.1118 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/15\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.0765 - accuracy: 0.2222 - val_loss: 3.1136 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/15\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.0752 - accuracy: 0.1667 - val_loss: 3.1154 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/15\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.0737 - accuracy: 0.2222 - val_loss: 3.1173 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/15\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.0721 - accuracy: 0.2222 - val_loss: 3.1192 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nmodel = Sequential()\\nmodel.add(Embedding(vocab_size, 10, input_length=max_length-1))\\nmodel.add(LSTM(50))\\nmodel.add(Dense(vocab_size, activation='softmax'))\\nprint(model.summary())\\n# compile network\\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\\n# fit network\\nmodel.fit(X, y, batch_size=32, epochs=500, verbose=2)\\n# evaluate model\\nprint(generate_seq(model, tokenizer, max_length-1, 'Jack and', 5))\\nprint(generate_seq(model, tokenizer, max_length-1, 'And Jill', 3))\\nprint(generate_seq(model, tokenizer, max_length-1, 'fell down', 5))\\nprint(generate_seq(model, tokenizer, max_length-1, 'pail of', 5))\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # source text\n",
    "# data = \"\"\" Jack and Jill went up the hill\\n\n",
    "# \t\tTo fetch a pail of water\\n\n",
    "# \t\tJack fell down and broke his crown\\n\n",
    "# \t\tAnd Jill came tumbling after\\n \"\"\"\n",
    "\n",
    "# integer encode sequences of words\n",
    "#https://stackoverflow.com/questions/51956000/what-does-keras-tokenizer-method-exactly-do\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "encoded = tokenizer.texts_to_sequences([data])[0]\n",
    "# retrieve vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)\n",
    "# encode 2 words -> 1 word\n",
    "sequences = list()\n",
    "for i in range(2, len(encoded)):\n",
    "    sequence = encoded[i-2:i+1]\n",
    "    sequences.append(sequence)\n",
    "print('Total Sequences: %d' % len(sequences))\n",
    "# pad sequences\n",
    "max_length = max([len(seq) for seq in sequences])\n",
    "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
    "print('Max Sequence Length: %d' % max_length)\n",
    "# split into input and output elements\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1],sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "# define model\n",
    "\n",
    "\n",
    "\n",
    "word_in = Input(shape=(max_length-1,))\n",
    "emb_word = Embedding(input_dim=vocab_size, output_dim=10,\n",
    "                     input_length=max_length-1, mask_zero=True)(word_in)\n",
    "main_lstm = LSTM(units=50, return_sequences=False,\n",
    "                               recurrent_dropout=0.6)(emb_word)\n",
    "\n",
    "outputs = Dense(vocab_size, activation='softmax')(main_lstm)\n",
    "model = Model(word_in, outputs)\n",
    "\n",
    "# compile network\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "model.fit(X, y, batch_size=32, epochs=15, validation_split=0.2, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=max_length-1))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())\n",
    "# compile network\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "model.fit(X, y, batch_size=32, epochs=500, verbose=2)\n",
    "# evaluate model\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'Jack and', 5))\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'And Jill', 3))\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'fell down', 5))\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'pail of', 5))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12ca6971-c3c7-4b47-8c69-fdd9812a0fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And Jill jack\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'Jack and', 1))\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'And Jill', 1))\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'fell down', 5))\n",
    "print(generate_seq(model, tokenizer, max_length-1, 'pail of', 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3add91fb-eaf1-4eeb-9ca5-4114991c0ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866d4ae7-a583-475e-ae13-18980ce1fdad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03a7f50-6740-4a2c-957b-b120fa5a8d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e9e728-96b6-4d21-be22-cbda99d3e0bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6415c84-383a-4eac-ade9-8f5f35130680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d9be3f-871e-4805-8f86-8b03ace54290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf427b2b-d1a4-4681-9594-ee546ffea32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language Model with our data\n",
    "data = list(df['title'])\n",
    "\n",
    "# data = data[:200]\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data)\n",
    "encoded_list = tokenizer.texts_to_sequences(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "599a2e40-7458-47e9-801d-98cddd5a8599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e9f9a2a-24b0-4036-8cb9-74c078c69fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1892 1000\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size, len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd0fcd36-b124-4bb9-ab45-63bfd68e07bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[447, 859, 860, 85, 598, 106, 599, 861, 862, 863],\n",
       " [18, 27, 288, 202, 448, 449, 864, 95, 236, 119, 5],\n",
       " [1, 865, 866, 96, 107, 867, 868, 97, 355, 5],\n",
       " [148, 450, 237, 13],\n",
       " [15, 25, 26, 451, 203, 600, 172, 601, 452, 869, 5]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bb5487a-846c-4591-ac64-a36bb06622c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Buffalo Games 1000-pc. Vivid Collection Sky Roads Jigsaw Puzzle',\n",
       " 'Girls Toddler Colosseum Crimson Oklahoma Sooners Scooter Plaid Button-Up Dress',\n",
       " \"Women's Refried Apparel Navy New England Patriots Maxi Tank Dress\",\n",
       " \"Candie's® Shawl-Collar Blazer\",\n",
       " \"Juniors' Plus Size Lily Rose Lantern-Sleeve French Terry Shift Dress\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9505bae-d359-4307-a181-29bb5c530148",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reconstructed = tokenizer.sequences_to_texts(encoded_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71f1222b-ace3-47ca-b178-39f43d4ca4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buffalo games 1000 pc vivid collection sky roads jigsaw puzzle',\n",
       " 'girls toddler colosseum crimson oklahoma sooners scooter plaid button up dress',\n",
       " \"women's refried apparel navy new england patriots maxi tank dress\",\n",
       " \"candie's® shawl collar blazer\",\n",
       " \"juniors' plus size lily rose lantern sleeve french terry shift dress\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reconstructed[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8019249d-feee-4ece-a5bb-760737341941",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_length = 5\n",
    "sequences = []\n",
    "for encoded in encoded_list:\n",
    "    for i in range(n_gram_length-1, len(encoded)):\n",
    "        sequence = encoded[i-(n_gram_length-1):i+1]\n",
    "        sequences.append(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8f70922-1ce3-4ab0-8f67-44d89a2b421d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3774"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c41bdf9-4ec5-4c3f-9bac-4cdbafb1065b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[447, 859, 860, 85, 598],\n",
       " [859, 860, 85, 598, 106],\n",
       " [860, 85, 598, 106, 599],\n",
       " [85, 598, 106, 599, 861],\n",
       " [598, 106, 599, 861, 862],\n",
       " [106, 599, 861, 862, 863],\n",
       " [18, 27, 288, 202, 448],\n",
       " [27, 288, 202, 448, 449],\n",
       " [288, 202, 448, 449, 864],\n",
       " [202, 448, 449, 864, 95]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fff3058-b3ad-4e18-a6aa-a07528bcbbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = pad_sequences(sequences, maxlen=n_gram_length, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efd44e02-cfd9-4876-8e7f-9461ba857c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[447, 859, 860,  85, 598],\n",
       "       [859, 860,  85, 598, 106],\n",
       "       [860,  85, 598, 106, 599],\n",
       "       [ 85, 598, 106, 599, 861],\n",
       "       [598, 106, 599, 861, 862]], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3615cdd7-11ec-483c-8395-f119722972d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3774"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cf7a9c1-fdcb-42a1-88a6-337d8ebc4798",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sequences[:,:-1],sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64ea5665-bdea-4465-a704-8208700ac4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([447, 859, 860,  85], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7f52cc3-ea07-4496-a17b-7bab46ef939e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64f4b2da-7a21-497b-8127-c915156e9005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1892"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5536a11e-83be-483a-8da6-19959206a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "41ff009b-cc78-4647-899c-5bf576e0050d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 4, 10)             18920     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 50)                12200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1892)              96492     \n",
      "=================================================================\n",
      "Total params: 127,612\n",
      "Trainable params: 127,612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# # define model\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(vocab_size, 10, input_length=n_gram_length-1))\n",
    "# model.add(LSTM(50))\n",
    "# model.add(Dense(vocab_size, activation='softmax'))\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d95ef74d-865d-4367-868e-83e2758a4fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1892"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45bdfda5-003e-4343-ab72-0b2fca46b487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/15\n",
      "95/95 [==============================] - 19s 26ms/step - loss: 7.4711 - accuracy: 0.0149 - val_loss: 6.7516 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/15\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 6.2594 - accuracy: 0.0232 - val_loss: 6.7456 - val_accuracy: 0.0384\n",
      "Epoch 3/15\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 6.0716 - accuracy: 0.0142 - val_loss: 6.8731 - val_accuracy: 0.0384\n",
      "Epoch 4/15\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 5.9771 - accuracy: 0.0192 - val_loss: 6.9358 - val_accuracy: 0.0437\n",
      "Epoch 5/15\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 5.9530 - accuracy: 0.0232 - val_loss: 7.0613 - val_accuracy: 0.0384\n",
      "Epoch 6/15\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 5.8914 - accuracy: 0.0197 - val_loss: 7.1690 - val_accuracy: 0.0543\n",
      "Epoch 7/15\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 5.8467 - accuracy: 0.0248 - val_loss: 7.2129 - val_accuracy: 0.0079\n",
      "Epoch 8/15\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 5.8769 - accuracy: 0.0197 - val_loss: 7.3573 - val_accuracy: 0.0437\n",
      "Epoch 9/15\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 5.8328 - accuracy: 0.0127 - val_loss: 7.4298 - val_accuracy: 0.0252\n",
      "Epoch 10/15\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 5.7925 - accuracy: 0.0175 - val_loss: 7.4399 - val_accuracy: 0.0503\n",
      "Epoch 11/15\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 5.7712 - accuracy: 0.0253 - val_loss: 7.5901 - val_accuracy: 0.0411\n",
      "Epoch 12/15\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 5.7088 - accuracy: 0.0304 - val_loss: 7.6617 - val_accuracy: 0.0384\n",
      "Epoch 13/15\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 5.7182 - accuracy: 0.0302 - val_loss: 7.8249 - val_accuracy: 0.0331\n",
      "Epoch 14/15\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 5.6669 - accuracy: 0.0396 - val_loss: 7.8898 - val_accuracy: 0.0278\n",
      "Epoch 15/15\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 5.6561 - accuracy: 0.0381 - val_loss: 8.0329 - val_accuracy: 0.0344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f356838d8e0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_in = Input(shape=(n_gram_length-1,))\n",
    "emb_word = Embedding(input_dim=vocab_size, output_dim=10,\n",
    "                     input_length=n_gram_length-1, mask_zero=True)(word_in)\n",
    "main_lstm = LSTM(units=50, return_sequences=False,\n",
    "                               recurrent_dropout=0.6)(emb_word)\n",
    "\n",
    "outputs = Dense(vocab_size, activation='softmax')(main_lstm)\n",
    "model = Model(word_in, outputs)\n",
    "\n",
    "# compile network\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "model.fit(X, y, batch_size=32, epochs=15, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "836ff300-6834-4ca0-aa63-6a2c782bcb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 5.5899 - accuracy: 0.0338 - val_loss: 8.1450 - val_accuracy: 0.0318\n",
      "Epoch 2/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 5.5367 - accuracy: 0.0358 - val_loss: 8.1774 - val_accuracy: 0.0358\n",
      "Epoch 3/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 5.4815 - accuracy: 0.0431 - val_loss: 8.2073 - val_accuracy: 0.0371\n",
      "Epoch 4/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 5.4234 - accuracy: 0.0397 - val_loss: 8.4131 - val_accuracy: 0.0384\n",
      "Epoch 5/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 5.3618 - accuracy: 0.0457 - val_loss: 8.4420 - val_accuracy: 0.0397\n",
      "Epoch 6/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 5.2901 - accuracy: 0.0480 - val_loss: 8.5107 - val_accuracy: 0.0132\n",
      "Epoch 7/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 5.2120 - accuracy: 0.0540 - val_loss: 8.5858 - val_accuracy: 0.0437\n",
      "Epoch 8/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 5.1348 - accuracy: 0.0553 - val_loss: 8.6292 - val_accuracy: 0.0464\n",
      "Epoch 9/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 5.0581 - accuracy: 0.0566 - val_loss: 8.6402 - val_accuracy: 0.0464\n",
      "Epoch 10/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 4.9900 - accuracy: 0.0682 - val_loss: 8.6685 - val_accuracy: 0.0503\n",
      "Epoch 11/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 4.9047 - accuracy: 0.0692 - val_loss: 8.7139 - val_accuracy: 0.0464\n",
      "Epoch 12/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 4.8344 - accuracy: 0.0772 - val_loss: 8.6685 - val_accuracy: 0.0556\n",
      "Epoch 13/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 4.7545 - accuracy: 0.0725 - val_loss: 8.6814 - val_accuracy: 0.0543\n",
      "Epoch 14/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 4.6981 - accuracy: 0.0918 - val_loss: 8.6954 - val_accuracy: 0.0636\n",
      "Epoch 15/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 4.6220 - accuracy: 0.0937 - val_loss: 8.7308 - val_accuracy: 0.0503\n",
      "Epoch 16/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 4.5643 - accuracy: 0.1020 - val_loss: 8.7675 - val_accuracy: 0.0570\n",
      "Epoch 17/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 4.5093 - accuracy: 0.0987 - val_loss: 8.7995 - val_accuracy: 0.0503\n",
      "Epoch 18/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 4.4487 - accuracy: 0.1169 - val_loss: 8.8175 - val_accuracy: 0.0583\n",
      "Epoch 19/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 4.3989 - accuracy: 0.1222 - val_loss: 8.8272 - val_accuracy: 0.0583\n",
      "Epoch 20/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 4.3323 - accuracy: 0.1249 - val_loss: 8.8412 - val_accuracy: 0.0530\n",
      "Epoch 21/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 4.2767 - accuracy: 0.1395 - val_loss: 8.8583 - val_accuracy: 0.0636\n",
      "Epoch 22/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 4.2310 - accuracy: 0.1391 - val_loss: 8.8411 - val_accuracy: 0.0583\n",
      "Epoch 23/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 4.1653 - accuracy: 0.1504 - val_loss: 8.8958 - val_accuracy: 0.0623\n",
      "Epoch 24/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 4.1459 - accuracy: 0.1510 - val_loss: 8.9060 - val_accuracy: 0.0623\n",
      "Epoch 25/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 4.0900 - accuracy: 0.1613 - val_loss: 8.9323 - val_accuracy: 0.0689\n",
      "Epoch 26/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 4.0422 - accuracy: 0.1633 - val_loss: 8.9811 - val_accuracy: 0.0636\n",
      "Epoch 27/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 3.9964 - accuracy: 0.1832 - val_loss: 8.9821 - val_accuracy: 0.0636\n",
      "Epoch 28/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 3.9445 - accuracy: 0.1815 - val_loss: 8.9571 - val_accuracy: 0.0689\n",
      "Epoch 29/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 3.8992 - accuracy: 0.1918 - val_loss: 8.9862 - val_accuracy: 0.0636\n",
      "Epoch 30/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 3.8578 - accuracy: 0.1981 - val_loss: 8.9834 - val_accuracy: 0.0662\n",
      "Epoch 31/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 3.8058 - accuracy: 0.2103 - val_loss: 9.0183 - val_accuracy: 0.0715\n",
      "Epoch 32/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 3.7535 - accuracy: 0.2163 - val_loss: 9.0005 - val_accuracy: 0.0755\n",
      "Epoch 33/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 3.7206 - accuracy: 0.2259 - val_loss: 8.9868 - val_accuracy: 0.0861\n",
      "Epoch 34/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 3.6749 - accuracy: 0.2219 - val_loss: 9.0059 - val_accuracy: 0.0861\n",
      "Epoch 35/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 3.6278 - accuracy: 0.2309 - val_loss: 9.0236 - val_accuracy: 0.0834\n",
      "Epoch 36/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 3.5877 - accuracy: 0.2491 - val_loss: 9.0565 - val_accuracy: 0.0755\n",
      "Epoch 37/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 3.5350 - accuracy: 0.2544 - val_loss: 9.0427 - val_accuracy: 0.0834\n",
      "Epoch 38/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 3.4930 - accuracy: 0.2660 - val_loss: 9.0532 - val_accuracy: 0.0887\n",
      "Epoch 39/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 3.4521 - accuracy: 0.2733 - val_loss: 9.0048 - val_accuracy: 0.0874\n",
      "Epoch 40/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 3.4095 - accuracy: 0.2895 - val_loss: 9.0545 - val_accuracy: 0.0927\n",
      "Epoch 41/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 3.3613 - accuracy: 0.2912 - val_loss: 9.0381 - val_accuracy: 0.1020\n",
      "Epoch 42/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 3.3175 - accuracy: 0.3041 - val_loss: 9.0728 - val_accuracy: 0.1099\n",
      "Epoch 43/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 3.2747 - accuracy: 0.3084 - val_loss: 9.0545 - val_accuracy: 0.1046\n",
      "Epoch 44/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 3.2325 - accuracy: 0.3140 - val_loss: 9.0661 - val_accuracy: 0.1113\n",
      "Epoch 45/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 3.1914 - accuracy: 0.3230 - val_loss: 9.0647 - val_accuracy: 0.1046\n",
      "Epoch 46/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 3.1442 - accuracy: 0.3332 - val_loss: 9.0806 - val_accuracy: 0.1113\n",
      "Epoch 47/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 3.0985 - accuracy: 0.3389 - val_loss: 9.0758 - val_accuracy: 0.1099\n",
      "Epoch 48/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 3.0598 - accuracy: 0.3498 - val_loss: 9.0957 - val_accuracy: 0.1033\n",
      "Epoch 49/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 3.0193 - accuracy: 0.3548 - val_loss: 9.0779 - val_accuracy: 0.1099\n",
      "Epoch 50/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 2.9815 - accuracy: 0.3607 - val_loss: 9.0894 - val_accuracy: 0.1073\n",
      "Epoch 51/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 2.9365 - accuracy: 0.3687 - val_loss: 9.0904 - val_accuracy: 0.1086\n",
      "Epoch 52/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 2.9118 - accuracy: 0.3720 - val_loss: 9.0780 - val_accuracy: 0.1086\n",
      "Epoch 53/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 2.8696 - accuracy: 0.3799 - val_loss: 9.0693 - val_accuracy: 0.1166\n",
      "Epoch 54/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 2.8290 - accuracy: 0.3842 - val_loss: 9.1166 - val_accuracy: 0.1166\n",
      "Epoch 55/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 2.7923 - accuracy: 0.3915 - val_loss: 9.0841 - val_accuracy: 0.1152\n",
      "Epoch 56/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 2.7475 - accuracy: 0.4048 - val_loss: 9.0886 - val_accuracy: 0.1139\n",
      "Epoch 57/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 2.7080 - accuracy: 0.4078 - val_loss: 9.1288 - val_accuracy: 0.1179\n",
      "Epoch 58/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 2.6769 - accuracy: 0.4154 - val_loss: 9.0976 - val_accuracy: 0.1179\n",
      "Epoch 59/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 2.6415 - accuracy: 0.4329 - val_loss: 9.1084 - val_accuracy: 0.1205\n",
      "Epoch 60/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 2.6036 - accuracy: 0.4392 - val_loss: 9.1017 - val_accuracy: 0.1272\n",
      "Epoch 61/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 2.5701 - accuracy: 0.4419 - val_loss: 9.1304 - val_accuracy: 0.1219\n",
      "Epoch 62/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 2.5290 - accuracy: 0.4419 - val_loss: 9.1329 - val_accuracy: 0.1298\n",
      "Epoch 63/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 2.5048 - accuracy: 0.4545 - val_loss: 9.1647 - val_accuracy: 0.1192\n",
      "Epoch 64/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 2.4756 - accuracy: 0.4538 - val_loss: 9.1760 - val_accuracy: 0.1205\n",
      "Epoch 65/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 2.4524 - accuracy: 0.4617 - val_loss: 9.1314 - val_accuracy: 0.1192\n",
      "Epoch 66/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 2.4031 - accuracy: 0.4783 - val_loss: 9.1628 - val_accuracy: 0.1338\n",
      "Epoch 67/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 2.3851 - accuracy: 0.4743 - val_loss: 9.1920 - val_accuracy: 0.1311\n",
      "Epoch 68/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 2.3443 - accuracy: 0.4872 - val_loss: 9.2216 - val_accuracy: 0.1391\n",
      "Epoch 69/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 2.3165 - accuracy: 0.4906 - val_loss: 9.2170 - val_accuracy: 0.1404\n",
      "Epoch 70/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 2.2686 - accuracy: 0.4955 - val_loss: 9.2111 - val_accuracy: 0.1351\n",
      "Epoch 71/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 2.2434 - accuracy: 0.5051 - val_loss: 9.2388 - val_accuracy: 0.1377\n",
      "Epoch 72/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 2.2267 - accuracy: 0.5144 - val_loss: 9.2442 - val_accuracy: 0.1338\n",
      "Epoch 73/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 2.1840 - accuracy: 0.5243 - val_loss: 9.2609 - val_accuracy: 0.1483\n",
      "Epoch 74/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 2.1710 - accuracy: 0.5273 - val_loss: 9.2678 - val_accuracy: 0.1391\n",
      "Epoch 75/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 2.1260 - accuracy: 0.5386 - val_loss: 9.2725 - val_accuracy: 0.1364\n",
      "Epoch 76/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 2.1167 - accuracy: 0.5429 - val_loss: 9.3067 - val_accuracy: 0.1470\n",
      "Epoch 77/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 2.0788 - accuracy: 0.5535 - val_loss: 9.2999 - val_accuracy: 0.1457\n",
      "Epoch 78/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 2.0399 - accuracy: 0.5624 - val_loss: 9.3293 - val_accuracy: 0.1497\n",
      "Epoch 79/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 2.0180 - accuracy: 0.5611 - val_loss: 9.3706 - val_accuracy: 0.1417\n",
      "Epoch 80/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 2.0051 - accuracy: 0.5760 - val_loss: 9.3498 - val_accuracy: 0.1470\n",
      "Epoch 81/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 1.9605 - accuracy: 0.5744 - val_loss: 9.3285 - val_accuracy: 0.1523\n",
      "Epoch 82/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.9375 - accuracy: 0.5770 - val_loss: 9.3883 - val_accuracy: 0.1417\n",
      "Epoch 83/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.9146 - accuracy: 0.5932 - val_loss: 9.3811 - val_accuracy: 0.1430\n",
      "Epoch 84/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 1.8870 - accuracy: 0.5956 - val_loss: 9.4012 - val_accuracy: 0.1404\n",
      "Epoch 85/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.8622 - accuracy: 0.5926 - val_loss: 9.4402 - val_accuracy: 0.1430\n",
      "Epoch 86/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 1.8404 - accuracy: 0.6035 - val_loss: 9.4154 - val_accuracy: 0.1444\n",
      "Epoch 87/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 1.8075 - accuracy: 0.6158 - val_loss: 9.4119 - val_accuracy: 0.1457\n",
      "Epoch 88/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.7899 - accuracy: 0.6184 - val_loss: 9.4500 - val_accuracy: 0.1470\n",
      "Epoch 89/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.7666 - accuracy: 0.6194 - val_loss: 9.4776 - val_accuracy: 0.1483\n",
      "Epoch 90/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 1.7431 - accuracy: 0.6290 - val_loss: 9.5009 - val_accuracy: 0.1444\n",
      "Epoch 91/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.7129 - accuracy: 0.6284 - val_loss: 9.5057 - val_accuracy: 0.1351\n",
      "Epoch 92/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.6851 - accuracy: 0.6429 - val_loss: 9.5238 - val_accuracy: 0.1404\n",
      "Epoch 93/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 1.6783 - accuracy: 0.6419 - val_loss: 9.5388 - val_accuracy: 0.1404\n",
      "Epoch 94/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.6481 - accuracy: 0.6529 - val_loss: 9.5382 - val_accuracy: 0.1444\n",
      "Epoch 95/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.6373 - accuracy: 0.6452 - val_loss: 9.5673 - val_accuracy: 0.1364\n",
      "Epoch 96/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 1.5941 - accuracy: 0.6611 - val_loss: 9.5652 - val_accuracy: 0.1404\n",
      "Epoch 97/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.5755 - accuracy: 0.6664 - val_loss: 9.5867 - val_accuracy: 0.1404\n",
      "Epoch 98/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 1.5544 - accuracy: 0.6698 - val_loss: 9.5856 - val_accuracy: 0.1430\n",
      "Epoch 99/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 1.5436 - accuracy: 0.6790 - val_loss: 9.6260 - val_accuracy: 0.1430\n",
      "Epoch 100/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.5259 - accuracy: 0.6860 - val_loss: 9.6332 - val_accuracy: 0.1457\n",
      "Epoch 101/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 1.4967 - accuracy: 0.6797 - val_loss: 9.6510 - val_accuracy: 0.1404\n",
      "Epoch 102/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 1.4813 - accuracy: 0.6886 - val_loss: 9.6926 - val_accuracy: 0.1404\n",
      "Epoch 103/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.4716 - accuracy: 0.6910 - val_loss: 9.6710 - val_accuracy: 0.1364\n",
      "Epoch 104/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.4373 - accuracy: 0.6986 - val_loss: 9.7056 - val_accuracy: 0.1417\n",
      "Epoch 105/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.4203 - accuracy: 0.7039 - val_loss: 9.7280 - val_accuracy: 0.1497\n",
      "Epoch 106/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.4082 - accuracy: 0.7098 - val_loss: 9.7148 - val_accuracy: 0.1457\n",
      "Epoch 107/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.3971 - accuracy: 0.7079 - val_loss: 9.7498 - val_accuracy: 0.1510\n",
      "Epoch 108/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 1.3652 - accuracy: 0.7138 - val_loss: 9.7398 - val_accuracy: 0.1523\n",
      "Epoch 109/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.3422 - accuracy: 0.7158 - val_loss: 9.7770 - val_accuracy: 0.1483\n",
      "Epoch 110/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.3397 - accuracy: 0.7198 - val_loss: 9.7819 - val_accuracy: 0.1444\n",
      "Epoch 111/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 1.3147 - accuracy: 0.7287 - val_loss: 9.8088 - val_accuracy: 0.1444\n",
      "Epoch 112/250\n",
      "95/95 [==============================] - 2s 19ms/step - loss: 1.2910 - accuracy: 0.7231 - val_loss: 9.8547 - val_accuracy: 0.1470\n",
      "Epoch 113/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.2781 - accuracy: 0.7373 - val_loss: 9.8457 - val_accuracy: 0.1470\n",
      "Epoch 114/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 1.2587 - accuracy: 0.7440 - val_loss: 9.8871 - val_accuracy: 0.1470\n",
      "Epoch 115/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.2457 - accuracy: 0.7363 - val_loss: 9.8875 - val_accuracy: 0.1457\n",
      "Epoch 116/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.2404 - accuracy: 0.7479 - val_loss: 9.9108 - val_accuracy: 0.1457\n",
      "Epoch 117/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 1.2163 - accuracy: 0.7476 - val_loss: 9.9229 - val_accuracy: 0.1470\n",
      "Epoch 118/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.1908 - accuracy: 0.7642 - val_loss: 9.9195 - val_accuracy: 0.1510\n",
      "Epoch 119/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.1817 - accuracy: 0.7602 - val_loss: 9.9479 - val_accuracy: 0.1483\n",
      "Epoch 120/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.1690 - accuracy: 0.7585 - val_loss: 9.9477 - val_accuracy: 0.1444\n",
      "Epoch 121/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.1544 - accuracy: 0.7615 - val_loss: 9.9775 - val_accuracy: 0.1470\n",
      "Epoch 122/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.1410 - accuracy: 0.7661 - val_loss: 10.0250 - val_accuracy: 0.1444\n",
      "Epoch 123/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.1337 - accuracy: 0.7685 - val_loss: 10.0290 - val_accuracy: 0.1483\n",
      "Epoch 124/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.1105 - accuracy: 0.7771 - val_loss: 10.0174 - val_accuracy: 0.1430\n",
      "Epoch 125/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.0989 - accuracy: 0.7724 - val_loss: 10.0548 - val_accuracy: 0.1444\n",
      "Epoch 126/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.0825 - accuracy: 0.7870 - val_loss: 10.0711 - val_accuracy: 0.1417\n",
      "Epoch 127/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 1.0649 - accuracy: 0.7827 - val_loss: 10.1011 - val_accuracy: 0.1510\n",
      "Epoch 128/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.0454 - accuracy: 0.7867 - val_loss: 10.1168 - val_accuracy: 0.1417\n",
      "Epoch 129/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.0425 - accuracy: 0.7870 - val_loss: 10.1316 - val_accuracy: 0.1497\n",
      "Epoch 130/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 1.0269 - accuracy: 0.7900 - val_loss: 10.1531 - val_accuracy: 0.1497\n",
      "Epoch 131/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.0199 - accuracy: 0.7946 - val_loss: 10.1854 - val_accuracy: 0.1457\n",
      "Epoch 132/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 1.0085 - accuracy: 0.7956 - val_loss: 10.1658 - val_accuracy: 0.1497\n",
      "Epoch 133/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.9937 - accuracy: 0.7963 - val_loss: 10.1815 - val_accuracy: 0.1457\n",
      "Epoch 134/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.9818 - accuracy: 0.7960 - val_loss: 10.1695 - val_accuracy: 0.1523\n",
      "Epoch 135/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.9672 - accuracy: 0.7956 - val_loss: 10.2058 - val_accuracy: 0.1523\n",
      "Epoch 136/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.9606 - accuracy: 0.8042 - val_loss: 10.2097 - val_accuracy: 0.1523\n",
      "Epoch 137/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.9539 - accuracy: 0.8076 - val_loss: 10.2456 - val_accuracy: 0.1470\n",
      "Epoch 138/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.9401 - accuracy: 0.8102 - val_loss: 10.2932 - val_accuracy: 0.1457\n",
      "Epoch 139/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.9292 - accuracy: 0.8032 - val_loss: 10.2765 - val_accuracy: 0.1510\n",
      "Epoch 140/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.9191 - accuracy: 0.8082 - val_loss: 10.3155 - val_accuracy: 0.1470\n",
      "Epoch 141/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.9020 - accuracy: 0.8158 - val_loss: 10.3328 - val_accuracy: 0.1430\n",
      "Epoch 142/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.8890 - accuracy: 0.8201 - val_loss: 10.3247 - val_accuracy: 0.1497\n",
      "Epoch 143/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.8863 - accuracy: 0.8231 - val_loss: 10.3603 - val_accuracy: 0.1497\n",
      "Epoch 144/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.8776 - accuracy: 0.8168 - val_loss: 10.3609 - val_accuracy: 0.1510\n",
      "Epoch 145/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.8567 - accuracy: 0.8238 - val_loss: 10.4087 - val_accuracy: 0.1457\n",
      "Epoch 146/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.8481 - accuracy: 0.8271 - val_loss: 10.4115 - val_accuracy: 0.1523\n",
      "Epoch 147/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.8434 - accuracy: 0.8228 - val_loss: 10.4282 - val_accuracy: 0.1483\n",
      "Epoch 148/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.8361 - accuracy: 0.8350 - val_loss: 10.4366 - val_accuracy: 0.1497\n",
      "Epoch 149/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.8115 - accuracy: 0.8417 - val_loss: 10.4701 - val_accuracy: 0.1457\n",
      "Epoch 150/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.8207 - accuracy: 0.8341 - val_loss: 10.4981 - val_accuracy: 0.1483\n",
      "Epoch 151/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.8023 - accuracy: 0.8387 - val_loss: 10.5060 - val_accuracy: 0.1483\n",
      "Epoch 152/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.7987 - accuracy: 0.8334 - val_loss: 10.4827 - val_accuracy: 0.1497\n",
      "Epoch 153/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.7892 - accuracy: 0.8397 - val_loss: 10.5492 - val_accuracy: 0.1470\n",
      "Epoch 154/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.7819 - accuracy: 0.8370 - val_loss: 10.5487 - val_accuracy: 0.1444\n",
      "Epoch 155/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.7666 - accuracy: 0.8473 - val_loss: 10.5628 - val_accuracy: 0.1483\n",
      "Epoch 156/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.7676 - accuracy: 0.8427 - val_loss: 10.5512 - val_accuracy: 0.1510\n",
      "Epoch 157/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.7493 - accuracy: 0.8453 - val_loss: 10.5719 - val_accuracy: 0.1470\n",
      "Epoch 158/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.7450 - accuracy: 0.8480 - val_loss: 10.6099 - val_accuracy: 0.1457\n",
      "Epoch 159/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.7389 - accuracy: 0.8456 - val_loss: 10.6119 - val_accuracy: 0.1510\n",
      "Epoch 160/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.7310 - accuracy: 0.8543 - val_loss: 10.6488 - val_accuracy: 0.1497\n",
      "Epoch 161/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.7176 - accuracy: 0.8519 - val_loss: 10.6573 - val_accuracy: 0.1536\n",
      "Epoch 162/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.7118 - accuracy: 0.8562 - val_loss: 10.6868 - val_accuracy: 0.1497\n",
      "Epoch 163/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.7151 - accuracy: 0.8509 - val_loss: 10.6725 - val_accuracy: 0.1483\n",
      "Epoch 164/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.6982 - accuracy: 0.8562 - val_loss: 10.7062 - val_accuracy: 0.1483\n",
      "Epoch 165/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.6837 - accuracy: 0.8592 - val_loss: 10.7185 - val_accuracy: 0.1510\n",
      "Epoch 166/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.6801 - accuracy: 0.8609 - val_loss: 10.7717 - val_accuracy: 0.1444\n",
      "Epoch 167/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.6910 - accuracy: 0.8523 - val_loss: 10.7849 - val_accuracy: 0.1510\n",
      "Epoch 168/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.6691 - accuracy: 0.8639 - val_loss: 10.7776 - val_accuracy: 0.1470\n",
      "Epoch 169/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.6652 - accuracy: 0.8569 - val_loss: 10.7776 - val_accuracy: 0.1523\n",
      "Epoch 170/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.6630 - accuracy: 0.8655 - val_loss: 10.7960 - val_accuracy: 0.1497\n",
      "Epoch 171/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.6507 - accuracy: 0.8592 - val_loss: 10.7758 - val_accuracy: 0.1497\n",
      "Epoch 172/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.6418 - accuracy: 0.8672 - val_loss: 10.8395 - val_accuracy: 0.1510\n",
      "Epoch 173/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.6352 - accuracy: 0.8682 - val_loss: 10.8095 - val_accuracy: 0.1523\n",
      "Epoch 174/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.6299 - accuracy: 0.8695 - val_loss: 10.8547 - val_accuracy: 0.1523\n",
      "Epoch 175/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.6248 - accuracy: 0.8672 - val_loss: 10.8604 - val_accuracy: 0.1483\n",
      "Epoch 176/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.6238 - accuracy: 0.8721 - val_loss: 10.8758 - val_accuracy: 0.1457\n",
      "Epoch 177/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.6129 - accuracy: 0.8675 - val_loss: 10.8755 - val_accuracy: 0.1470\n",
      "Epoch 178/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.6033 - accuracy: 0.8738 - val_loss: 10.9248 - val_accuracy: 0.1444\n",
      "Epoch 179/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.6090 - accuracy: 0.8682 - val_loss: 10.9239 - val_accuracy: 0.1497\n",
      "Epoch 180/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.5928 - accuracy: 0.8738 - val_loss: 10.9421 - val_accuracy: 0.1444\n",
      "Epoch 181/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.5929 - accuracy: 0.8738 - val_loss: 10.9504 - val_accuracy: 0.1510\n",
      "Epoch 182/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.5893 - accuracy: 0.8725 - val_loss: 10.9664 - val_accuracy: 0.1510\n",
      "Epoch 183/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.5821 - accuracy: 0.8784 - val_loss: 10.9948 - val_accuracy: 0.1444\n",
      "Epoch 184/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.5796 - accuracy: 0.8784 - val_loss: 11.0145 - val_accuracy: 0.1470\n",
      "Epoch 185/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.5769 - accuracy: 0.8735 - val_loss: 10.9911 - val_accuracy: 0.1497\n",
      "Epoch 186/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.5682 - accuracy: 0.8788 - val_loss: 11.0014 - val_accuracy: 0.1483\n",
      "Epoch 187/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.5564 - accuracy: 0.8814 - val_loss: 11.0227 - val_accuracy: 0.1483\n",
      "Epoch 188/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.5550 - accuracy: 0.8784 - val_loss: 11.0247 - val_accuracy: 0.1483\n",
      "Epoch 189/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.5555 - accuracy: 0.8831 - val_loss: 11.0375 - val_accuracy: 0.1483\n",
      "Epoch 190/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.5450 - accuracy: 0.8798 - val_loss: 11.0865 - val_accuracy: 0.1483\n",
      "Epoch 191/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.5376 - accuracy: 0.8861 - val_loss: 11.0759 - val_accuracy: 0.1523\n",
      "Epoch 192/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.5374 - accuracy: 0.8861 - val_loss: 11.0950 - val_accuracy: 0.1444\n",
      "Epoch 193/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.5271 - accuracy: 0.8837 - val_loss: 11.1096 - val_accuracy: 0.1483\n",
      "Epoch 194/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.5271 - accuracy: 0.8811 - val_loss: 11.0875 - val_accuracy: 0.1510\n",
      "Epoch 195/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.5252 - accuracy: 0.8864 - val_loss: 11.1266 - val_accuracy: 0.1483\n",
      "Epoch 196/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.5243 - accuracy: 0.8851 - val_loss: 11.1168 - val_accuracy: 0.1497\n",
      "Epoch 197/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.5150 - accuracy: 0.8867 - val_loss: 11.1878 - val_accuracy: 0.1483\n",
      "Epoch 198/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.5131 - accuracy: 0.8897 - val_loss: 11.1920 - val_accuracy: 0.1444\n",
      "Epoch 199/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.5059 - accuracy: 0.8867 - val_loss: 11.1787 - val_accuracy: 0.1470\n",
      "Epoch 200/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.5023 - accuracy: 0.8880 - val_loss: 11.2449 - val_accuracy: 0.1457\n",
      "Epoch 201/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4968 - accuracy: 0.8914 - val_loss: 11.2023 - val_accuracy: 0.1497\n",
      "Epoch 202/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4933 - accuracy: 0.8943 - val_loss: 11.2382 - val_accuracy: 0.1470\n",
      "Epoch 203/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4904 - accuracy: 0.8874 - val_loss: 11.2258 - val_accuracy: 0.1497\n",
      "Epoch 204/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4882 - accuracy: 0.8907 - val_loss: 11.2524 - val_accuracy: 0.1497\n",
      "Epoch 205/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4779 - accuracy: 0.8910 - val_loss: 11.3034 - val_accuracy: 0.1470\n",
      "Epoch 206/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4821 - accuracy: 0.8917 - val_loss: 11.2370 - val_accuracy: 0.1470\n",
      "Epoch 207/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4827 - accuracy: 0.8933 - val_loss: 11.2536 - val_accuracy: 0.1523\n",
      "Epoch 208/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4711 - accuracy: 0.8904 - val_loss: 11.2976 - val_accuracy: 0.1444\n",
      "Epoch 209/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4684 - accuracy: 0.8920 - val_loss: 11.3008 - val_accuracy: 0.1470\n",
      "Epoch 210/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4735 - accuracy: 0.8904 - val_loss: 11.3210 - val_accuracy: 0.1470\n",
      "Epoch 211/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4692 - accuracy: 0.8887 - val_loss: 11.3123 - val_accuracy: 0.1510\n",
      "Epoch 212/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4550 - accuracy: 0.8957 - val_loss: 11.3279 - val_accuracy: 0.1483\n",
      "Epoch 213/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4528 - accuracy: 0.8904 - val_loss: 11.3473 - val_accuracy: 0.1497\n",
      "Epoch 214/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4489 - accuracy: 0.8967 - val_loss: 11.3521 - val_accuracy: 0.1470\n",
      "Epoch 215/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4568 - accuracy: 0.8940 - val_loss: 11.3688 - val_accuracy: 0.1483\n",
      "Epoch 216/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4486 - accuracy: 0.8890 - val_loss: 11.3469 - val_accuracy: 0.1497\n",
      "Epoch 217/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4462 - accuracy: 0.8930 - val_loss: 11.3658 - val_accuracy: 0.1470\n",
      "Epoch 218/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4391 - accuracy: 0.8973 - val_loss: 11.3701 - val_accuracy: 0.1470\n",
      "Epoch 219/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4413 - accuracy: 0.8996 - val_loss: 11.3628 - val_accuracy: 0.1510\n",
      "Epoch 220/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4331 - accuracy: 0.8986 - val_loss: 11.3867 - val_accuracy: 0.1523\n",
      "Epoch 221/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4308 - accuracy: 0.8980 - val_loss: 11.4119 - val_accuracy: 0.1470\n",
      "Epoch 222/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.4247 - accuracy: 0.8990 - val_loss: 11.4233 - val_accuracy: 0.1523\n",
      "Epoch 223/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4246 - accuracy: 0.9003 - val_loss: 11.4475 - val_accuracy: 0.1470\n",
      "Epoch 224/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.4227 - accuracy: 0.8996 - val_loss: 11.4539 - val_accuracy: 0.1510\n",
      "Epoch 225/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.4177 - accuracy: 0.9013 - val_loss: 11.4657 - val_accuracy: 0.1497\n",
      "Epoch 226/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4233 - accuracy: 0.8953 - val_loss: 11.4848 - val_accuracy: 0.1497\n",
      "Epoch 227/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4169 - accuracy: 0.8996 - val_loss: 11.4958 - val_accuracy: 0.1470\n",
      "Epoch 228/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4167 - accuracy: 0.8980 - val_loss: 11.5252 - val_accuracy: 0.1497\n",
      "Epoch 229/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4163 - accuracy: 0.8976 - val_loss: 11.5437 - val_accuracy: 0.1523\n",
      "Epoch 230/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4131 - accuracy: 0.9029 - val_loss: 11.5217 - val_accuracy: 0.1523\n",
      "Epoch 231/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4091 - accuracy: 0.9036 - val_loss: 11.5572 - val_accuracy: 0.1470\n",
      "Epoch 232/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4028 - accuracy: 0.9010 - val_loss: 11.5564 - val_accuracy: 0.1510\n",
      "Epoch 233/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.4044 - accuracy: 0.9013 - val_loss: 11.5513 - val_accuracy: 0.1510\n",
      "Epoch 234/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.4010 - accuracy: 0.9010 - val_loss: 11.5625 - val_accuracy: 0.1510\n",
      "Epoch 235/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.3957 - accuracy: 0.8996 - val_loss: 11.5841 - val_accuracy: 0.1510\n",
      "Epoch 236/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.4004 - accuracy: 0.9003 - val_loss: 11.6006 - val_accuracy: 0.1536\n",
      "Epoch 237/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.3947 - accuracy: 0.9013 - val_loss: 11.6041 - val_accuracy: 0.1523\n",
      "Epoch 238/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.3912 - accuracy: 0.9043 - val_loss: 11.6090 - val_accuracy: 0.1523\n",
      "Epoch 239/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.3889 - accuracy: 0.9006 - val_loss: 11.6198 - val_accuracy: 0.1510\n",
      "Epoch 240/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.3848 - accuracy: 0.9069 - val_loss: 11.6137 - val_accuracy: 0.1523\n",
      "Epoch 241/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.3932 - accuracy: 0.9006 - val_loss: 11.6327 - val_accuracy: 0.1536\n",
      "Epoch 242/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.3806 - accuracy: 0.9053 - val_loss: 11.6855 - val_accuracy: 0.1523\n",
      "Epoch 243/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.3810 - accuracy: 0.9020 - val_loss: 11.6870 - val_accuracy: 0.1523\n",
      "Epoch 244/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.3827 - accuracy: 0.9023 - val_loss: 11.6863 - val_accuracy: 0.1550\n",
      "Epoch 245/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.3802 - accuracy: 0.9046 - val_loss: 11.6858 - val_accuracy: 0.1550\n",
      "Epoch 246/250\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.3782 - accuracy: 0.9092 - val_loss: 11.7014 - val_accuracy: 0.1603\n",
      "Epoch 247/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.3759 - accuracy: 0.9039 - val_loss: 11.7212 - val_accuracy: 0.1550\n",
      "Epoch 248/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.3731 - accuracy: 0.9033 - val_loss: 11.7233 - val_accuracy: 0.1563\n",
      "Epoch 249/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.3755 - accuracy: 0.9033 - val_loss: 11.7491 - val_accuracy: 0.1550\n",
      "Epoch 250/250\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.3705 - accuracy: 0.9076 - val_loss: 11.7466 - val_accuracy: 0.1536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f355c5f4ca0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=32, epochs=250, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98927c2c-eed4-4fb7-9e10-f73f4bb2f35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, max_length, seed_text, n_words):\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # pre-pad sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat_preds = model.predict(encoded, verbose=0)\n",
    "        yhat = np.argmax(yhat_preds,axis=-1)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95ef70e1-cf8f-4078-bf37-a0f502a823da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add code to evaluate stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906df96e-d3c5-4654-8e5e-150896d45600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff42862-3a0c-450f-bf81-de62c74f84cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f916864-074f-4dfb-a507-7c2cea31d5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9951efb-4bec-47a8-a197-4703563ed7be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e8860d3-a675-4e14-89e7-666e0a4d2ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets try language model with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "780abe6e-0cec-4f76-9086-4893704a1cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 72.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /home/ubuntu/env/lib/python3.8/site-packages (from transformers) (4.61.0)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 107.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/ubuntu/env/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: requests in /home/ubuntu/env/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 110.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub==0.0.12\n",
      "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/env/lib/python3.8/site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/env/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/env/lib/python3.8/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: typing-extensions in /home/ubuntu/env/lib/python3.8/site-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ubuntu/env/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ubuntu/env/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ubuntu/env/lib/python3.8/site-packages (from requests->transformers) (1.26.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ubuntu/env/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/env/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: click in /home/ubuntu/env/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /home/ubuntu/env/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/env/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Installing collected packages: filelock, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.0.12 huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.1\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/env/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "391bd4c7-9285-43b1-9641-58466b93c3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets==7.4.2\n",
      "  Downloading ipywidgets-7.4.2-py2.py3-none-any.whl (111 kB)\n",
      "\u001b[K     |████████████████████████████████| 111 kB 22.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nbformat>=4.2.0 in /home/ubuntu/env/lib/python3.8/site-packages (from ipywidgets==7.4.2) (5.1.3)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/ubuntu/env/lib/python3.8/site-packages (from ipywidgets==7.4.2) (5.5.5)\n",
      "Collecting widgetsnbextension~=3.4.0\n",
      "  Downloading widgetsnbextension-3.4.2-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 62.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipython>=4.0.0 in /home/ubuntu/env/lib/python3.8/site-packages (from ipywidgets==7.4.2) (7.24.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/ubuntu/env/lib/python3.8/site-packages (from ipywidgets==7.4.2) (5.0.5)\n",
      "Requirement already satisfied: jupyter-client in /home/ubuntu/env/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets==7.4.2) (6.1.12)\n",
      "Requirement already satisfied: tornado>=4.2 in /home/ubuntu/env/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets==7.4.2) (6.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/ubuntu/env/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets==7.4.2) (4.8.0)\n",
      "Requirement already satisfied: matplotlib-inline in /home/ubuntu/env/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets==7.4.2) (0.1.2)\n",
      "Requirement already satisfied: pygments in /home/ubuntu/env/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets==7.4.2) (2.9.0)\n",
      "Requirement already satisfied: decorator in /home/ubuntu/env/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets==7.4.2) (4.4.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/ubuntu/env/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets==7.4.2) (3.0.18)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/ubuntu/env/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets==7.4.2) (56.0.0)\n",
      "Requirement already satisfied: backcall in /home/ubuntu/env/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets==7.4.2) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/ubuntu/env/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets==7.4.2) (0.18.0)\n",
      "Requirement already satisfied: pickleshare in /home/ubuntu/env/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets==7.4.2) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/ubuntu/env/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets==7.4.2) (0.8.2)\n",
      "Requirement already satisfied: ipython-genutils in /home/ubuntu/env/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets==7.4.2) (0.2.0)\n",
      "Requirement already satisfied: jupyter-core in /home/ubuntu/env/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets==7.4.2) (4.7.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /home/ubuntu/env/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets==7.4.2) (3.2.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/ubuntu/env/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets==7.4.2) (1.15.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ubuntu/env/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets==7.4.2) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/ubuntu/env/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets==7.4.2) (21.2.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/ubuntu/env/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets==7.4.2) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/ubuntu/env/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets==7.4.2) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /home/ubuntu/env/lib/python3.8/site-packages (from widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (6.4.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /home/ubuntu/env/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (1.5.0)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/env/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (3.0.1)\n",
      "Requirement already satisfied: nbconvert in /home/ubuntu/env/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (6.0.7)\n",
      "Requirement already satisfied: prometheus-client in /home/ubuntu/env/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (0.11.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /home/ubuntu/env/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (22.1.0)\n",
      "Requirement already satisfied: argon2-cffi in /home/ubuntu/env/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (20.1.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/ubuntu/env/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ubuntu/env/lib/python3.8/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets==7.4.2) (2.8.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /home/ubuntu/env/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /home/ubuntu/env/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/env/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (2.0.1)\n",
      "Requirement already satisfied: bleach in /home/ubuntu/env/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (3.3.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /home/ubuntu/env/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (0.8.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /home/ubuntu/env/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (0.3)\n",
      "Requirement already satisfied: testpath in /home/ubuntu/env/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (0.5.0)\n",
      "Requirement already satisfied: defusedxml in /home/ubuntu/env/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (0.7.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /home/ubuntu/env/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (0.5.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/ubuntu/env/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (1.4.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/ubuntu/env/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (0.1.2)\n",
      "Requirement already satisfied: nest-asyncio in /home/ubuntu/env/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (1.5.1)\n",
      "Requirement already satisfied: async-generator in /home/ubuntu/env/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (1.10)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/env/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (20.9)\n",
      "Requirement already satisfied: webencodings in /home/ubuntu/env/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ubuntu/env/lib/python3.8/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets==7.4.2) (2.4.7)\n",
      "Installing collected packages: widgetsnbextension, ipywidgets\n",
      "  Attempting uninstall: widgetsnbextension\n",
      "    Found existing installation: widgetsnbextension 3.5.1\n",
      "    Uninstalling widgetsnbextension-3.5.1:\n",
      "      Successfully uninstalled widgetsnbextension-3.5.1\n",
      "  Attempting uninstall: ipywidgets\n",
      "    Found existing installation: ipywidgets 7.6.3\n",
      "    Uninstalling ipywidgets-7.6.3:\n",
      "      Successfully uninstalled ipywidgets-7.6.3\n",
      "Successfully installed ipywidgets-7.4.2 widgetsnbextension-3.4.2\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/env/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets==7.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cdf2b7e-6647-417e-b444-cc2896bf6a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import logging\n",
    "import keras\n",
    "import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30e31568-b0ce-471c-9750-9f08b99484a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Model, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "075f9df3-e7b0-415c-80bb-5070b9d6a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "618e231c-5532-4ed4-8c4f-695827d67d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59c47d5a-1f0e-422e-a3b1-7668407fa870",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRETRAINED_MODEL = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e426b203-d52a-495b-9939-240237e0d7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187f0840168e425d8415f95a869aae03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59871382fdc49eea41c40fdacdf55c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/536M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForMaskedLM.from_pretrained(PRETRAINED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6f3dc4d-2c17-42aa-ada3-945cb970bb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "module_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2'\n",
    "bert_layer = hub.KerasLayer(module_url, trainable=True)\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed782f8f-b2de-4a53-8c41-860452f3a586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d970c10eea8d4b3d9b8b97dfb1cae0ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43904ade57b34dffb37a05c40e6313c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38da0d64adf843eda25bd434c5593af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70da0745-8d2d-44d5-a504-47eafc6da5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc729a47-a946-4f57-8577-f1828a4f9621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_predictions(text_sentence, top_clean=5):\n",
    "    # ========================= BERT =================================\n",
    "    input_ids, mask_idx = encode(bert_tokenizer, text_sentence)\n",
    "    with torch.no_grad():\n",
    "        predict = bert_model(input_ids)[0]\n",
    "    bert = decode(bert_tokenizer, predict[0, mask_idx, :].topk(top_k).indices.tolist(), top_clean)\n",
    "    return {'bert': bert}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc47d20-be55-43ba-b457-e0254ab2cef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_eos(input_text):\n",
    "    try:\n",
    "        input_text += ' <mask>'\n",
    "        res = get_all_predictions(input_text, top_clean=int(top_k))\n",
    "        return res\n",
    "    except Exception as error:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f5025d2-f06e-4e18-9d01-b90287e0abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    " inputs = bert_tokenizer(\"The capital of France is [MASK].\", return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5543ecb5-d4dd-408a-99ab-eb960fc37100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 9), dtype=int32, numpy=\n",
       "array([[ 101, 1996, 3007, 1997, 2605, 2003,  103, 1012,  102]],\n",
       "      dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1, 9), dtype=int32, numpy=array([[0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 9), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1230a3f5-ef17-415a-b646-c3248a2ef54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = [bert_tokenizer.tokenize(sent) for sent in \"The capital of France is [MASK].\".split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c7bfa96-e585-4a2d-9db4-7ee925415512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the'], ['capital'], ['of'], ['france'], ['is'], ['[MASK]', '.']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbb97d4b-e4a0-4569-94fa-ede4bbe38003",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = bert_tokenizer(\"The capital of France is [MASK].\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87e10d72-aa20-400c-830d-fc9727d02438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1996, 3007, 1997, 2605, 2003, 103, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9510f697-49c5-47e4-9c08-af35c6d16b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_masked_lm\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  108891648 \n",
      "_________________________________________________________________\n",
      "mlm___cls (TFBertMLMHead)    multiple                  24459834  \n",
      "=================================================================\n",
      "Total params: 109,514,298\n",
      "Trainable params: 109,514,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc73c264-2bf4-46b7-b793-a7bf70968a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7ff811b92ca0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7ff811b92ca0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7ff811b92ca0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/env/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/env/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n"
     ]
    }
   ],
   "source": [
    "outputs = model.predict([tokenized_texts['input_ids'], tokenized_texts['attention_mask'], tokenized_texts['token_type_ids']], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2910848-365e-4841-ac4f-40a1b67a7022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFMaskedLMOutput(loss=None, logits=array([[[ -6.4346046,  -6.4063444,  -6.4097404, ...,  -5.7691364,\n",
       "          -5.6326175,  -3.788285 ],\n",
       "        [-14.011925 , -14.724042 , -14.211972 , ..., -11.697638 ,\n",
       "         -10.730408 , -12.761747 ],\n",
       "        [ -9.656142 , -10.312491 ,  -9.745864 , ...,  -8.77816  ,\n",
       "          -6.603594 , -12.659599 ],\n",
       "        ...,\n",
       "        [ -3.7861156,  -3.857192 ,  -3.5644355, ...,  -2.5592554,\n",
       "          -3.109321 ,  -4.3819613],\n",
       "        [-11.659789 , -11.427393 , -11.926661 , ...,  -9.877244 ,\n",
       "         -10.210293 ,  -4.7594104],\n",
       "        [-11.72665  , -11.750851 , -11.803964 , ..., -10.594329 ,\n",
       "         -10.940653 ,  -7.5151176]],\n",
       "\n",
       "       [[ -4.9389725,  -5.101129 ,  -5.156227 , ...,  -4.9596376,\n",
       "          -6.8469996,   0.8288686],\n",
       "        [ -4.7209363,  -4.92056  ,  -4.9808407, ...,  -4.663267 ,\n",
       "          -6.56871  ,   0.7187822],\n",
       "        [ -4.357745 ,  -4.537199 ,  -4.620675 , ...,  -4.39608  ,\n",
       "          -6.212288 ,   0.9897884],\n",
       "        ...,\n",
       "        [ -3.999114 ,  -4.148432 ,  -4.211567 , ...,  -3.867784 ,\n",
       "          -5.6809707,   1.6085873],\n",
       "        [ -3.9150922,  -4.073153 ,  -4.128083 , ...,  -3.7460492,\n",
       "          -5.5528736,   1.6169617],\n",
       "        [ -3.9032674,  -4.072715 ,  -4.1080666, ...,  -3.689986 ,\n",
       "          -5.5356092,   1.445348 ]],\n",
       "\n",
       "       [[ -5.88022  ,  -6.24131  ,  -6.2423096, ...,  -5.669744 ,\n",
       "          -7.62073  ,   0.8102267],\n",
       "        [ -5.4617224,  -5.9175014,  -5.888833 , ...,  -5.2353907,\n",
       "          -7.2269073,   1.0121037],\n",
       "        [ -4.939167 ,  -5.361868 ,  -5.3674946, ...,  -4.8439946,\n",
       "          -6.732899 ,   1.3359776],\n",
       "        ...,\n",
       "        [ -4.559476 ,  -4.9554367,  -4.923314 , ...,  -4.0819097,\n",
       "          -6.231656 ,   1.8605869],\n",
       "        [ -4.506914 ,  -4.909583 ,  -4.872443 , ...,  -4.0092707,\n",
       "          -6.1339345,   1.8367889],\n",
       "        [ -4.5744567,  -4.98623  ,  -4.930628 , ...,  -4.0309024,\n",
       "          -6.122711 ,   1.567734 ]]], dtype=float32), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c737d0b-3077-4ba4-8b65-cafe2afd2a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5792ee0-663c-429a-aea5-caceac9e69b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ -6.4346046,  -6.4063444,  -6.4097404, ...,  -5.7691364,\n",
       "          -5.6326175,  -3.788285 ],\n",
       "        [-14.011925 , -14.724042 , -14.211972 , ..., -11.697638 ,\n",
       "         -10.730408 , -12.761747 ],\n",
       "        [ -9.656142 , -10.312491 ,  -9.745864 , ...,  -8.77816  ,\n",
       "          -6.603594 , -12.659599 ],\n",
       "        ...,\n",
       "        [ -3.7861156,  -3.857192 ,  -3.5644355, ...,  -2.5592554,\n",
       "          -3.109321 ,  -4.3819613],\n",
       "        [-11.659789 , -11.427393 , -11.926661 , ...,  -9.877244 ,\n",
       "         -10.210293 ,  -4.7594104],\n",
       "        [-11.72665  , -11.750851 , -11.803964 , ..., -10.594329 ,\n",
       "         -10.940653 ,  -7.5151176]],\n",
       "\n",
       "       [[ -4.9389725,  -5.101129 ,  -5.156227 , ...,  -4.9596376,\n",
       "          -6.8469996,   0.8288686],\n",
       "        [ -4.7209363,  -4.92056  ,  -4.9808407, ...,  -4.663267 ,\n",
       "          -6.56871  ,   0.7187822],\n",
       "        [ -4.357745 ,  -4.537199 ,  -4.620675 , ...,  -4.39608  ,\n",
       "          -6.212288 ,   0.9897884],\n",
       "        ...,\n",
       "        [ -3.999114 ,  -4.148432 ,  -4.211567 , ...,  -3.867784 ,\n",
       "          -5.6809707,   1.6085873],\n",
       "        [ -3.9150922,  -4.073153 ,  -4.128083 , ...,  -3.7460492,\n",
       "          -5.5528736,   1.6169617],\n",
       "        [ -3.9032674,  -4.072715 ,  -4.1080666, ...,  -3.689986 ,\n",
       "          -5.5356092,   1.445348 ]],\n",
       "\n",
       "       [[ -5.88022  ,  -6.24131  ,  -6.2423096, ...,  -5.669744 ,\n",
       "          -7.62073  ,   0.8102267],\n",
       "        [ -5.4617224,  -5.9175014,  -5.888833 , ...,  -5.2353907,\n",
       "          -7.2269073,   1.0121037],\n",
       "        [ -4.939167 ,  -5.361868 ,  -5.3674946, ...,  -4.8439946,\n",
       "          -6.732899 ,   1.3359776],\n",
       "        ...,\n",
       "        [ -4.559476 ,  -4.9554367,  -4.923314 , ...,  -4.0819097,\n",
       "          -6.231656 ,   1.8605869],\n",
       "        [ -4.506914 ,  -4.909583 ,  -4.872443 , ...,  -4.0092707,\n",
       "          -6.1339345,   1.8367889],\n",
       "        [ -4.5744567,  -4.98623  ,  -4.930628 , ...,  -4.0309024,\n",
       "          -6.122711 ,   1.567734 ]]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "999d4b37-2be6-4d54-93b1-173ec443238b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 9, 30522)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2befd50-0cfd-4a2d-b317-6924a0d6cc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ -6.4346046,  -6.4063444,  -6.4097404, ...,  -5.7691364,\n",
       "          -5.6326175,  -3.788285 ],\n",
       "        [-14.011925 , -14.724042 , -14.211972 , ..., -11.697638 ,\n",
       "         -10.730408 , -12.761747 ],\n",
       "        [ -9.656142 , -10.312491 ,  -9.745864 , ...,  -8.77816  ,\n",
       "          -6.603594 , -12.659599 ],\n",
       "        ...,\n",
       "        [ -3.7861156,  -3.857192 ,  -3.5644355, ...,  -2.5592554,\n",
       "          -3.109321 ,  -4.3819613],\n",
       "        [-11.659789 , -11.427393 , -11.926661 , ...,  -9.877244 ,\n",
       "         -10.210293 ,  -4.7594104],\n",
       "        [-11.72665  , -11.750851 , -11.803964 , ..., -10.594329 ,\n",
       "         -10.940653 ,  -7.5151176]],\n",
       "\n",
       "       [[ -4.9389725,  -5.101129 ,  -5.156227 , ...,  -4.9596376,\n",
       "          -6.8469996,   0.8288686],\n",
       "        [ -4.7209363,  -4.92056  ,  -4.9808407, ...,  -4.663267 ,\n",
       "          -6.56871  ,   0.7187822],\n",
       "        [ -4.357745 ,  -4.537199 ,  -4.620675 , ...,  -4.39608  ,\n",
       "          -6.212288 ,   0.9897884],\n",
       "        ...,\n",
       "        [ -3.999114 ,  -4.148432 ,  -4.211567 , ...,  -3.867784 ,\n",
       "          -5.6809707,   1.6085873],\n",
       "        [ -3.9150922,  -4.073153 ,  -4.128083 , ...,  -3.7460492,\n",
       "          -5.5528736,   1.6169617],\n",
       "        [ -3.9032674,  -4.072715 ,  -4.1080666, ...,  -3.689986 ,\n",
       "          -5.5356092,   1.445348 ]],\n",
       "\n",
       "       [[ -5.88022  ,  -6.24131  ,  -6.2423096, ...,  -5.669744 ,\n",
       "          -7.62073  ,   0.8102267],\n",
       "        [ -5.4617224,  -5.9175014,  -5.888833 , ...,  -5.2353907,\n",
       "          -7.2269073,   1.0121037],\n",
       "        [ -4.939167 ,  -5.361868 ,  -5.3674946, ...,  -4.8439946,\n",
       "          -6.732899 ,   1.3359776],\n",
       "        ...,\n",
       "        [ -4.559476 ,  -4.9554367,  -4.923314 , ...,  -4.0819097,\n",
       "          -6.231656 ,   1.8605869],\n",
       "        [ -4.506914 ,  -4.909583 ,  -4.872443 , ...,  -4.0092707,\n",
       "          -6.1339345,   1.8367889],\n",
       "        [ -4.5744567,  -4.98623  ,  -4.930628 , ...,  -4.0309024,\n",
       "          -6.122711 ,   1.567734 ]]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88741889-458e-47d1-9521-e8593e48fefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 9, 30522)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c50d4f9-1b2e-45ae-9e52-017fdef6fb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[MASK]'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97640017-97ed-4a99-ad56-cbe34c2b407d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 103, 102], 'token_type_ids': [0, 0, 0], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer('[MASK]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "726e9758-c509-4629-a91d-e4c51c438df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_idx = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64ec91ef-7940-46d5-ac34-ccb33d7f7dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = logits[0, mask_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0775de1-6be4-4d3e-9e94-c92b23b5bce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.7861156, -3.857192 , -3.5644355, ..., -2.5592554, -3.109321 ,\n",
       "       -4.3819613], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e42b534-fa00-48c4-bf87-cef8a886c2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30522,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "006dcef2-b71c-4b08-bc47-b8545fd78d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_index = np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f91c7c2f-0899-4d9a-96c7-c81255f88f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a79ab49-66a3-4463-944c-826fb44c85b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paris'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.decode([vocab_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc8c36ae-61ee-4d56-9985-a95c3dd1aee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninputs = tokenizer(\"The capital of France is [MASK].\", return_tensors=\"tf\")\\ninputs[\"labels\"] = tokenizer(\"The capital of France is Paris.\", return_tensors=\"tf\")[\"input_ids\"]\\n\\noutputs = model(inputs)\\nloss = outputs.loss\\nlogits = outputs.logits\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    ">>> inputs = tokenizer(\"The capital of France is [MASK].\", return_tensors=\"tf\")\n",
    ">>> inputs[\"labels\"] = tokenizer(\"The capital of France is Paris.\", return_tensors=\"tf\")[\"input_ids\"]\n",
    "\n",
    ">>> outputs = model(inputs)\n",
    ">>> loss = outputs.loss\n",
    ">>> logits = outputs.logits\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f54b53-278c-425e-b6c6-683b46351135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d60c9aa5-dec5-479c-a76b-b1071ec9aa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cd81765a-b0c4-4a6d-a640-b2e6675b367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ALL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "deafa930-4c75-4434-9c27-1e994b0fedc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "72e92162-3568-4ae7-8065-8fa7c4fff968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>index</th>\n",
       "      <th>created_at</th>\n",
       "      <th>feedback</th>\n",
       "      <th>metadata</th>\n",
       "      <th>searchimageurl</th>\n",
       "      <th>mathpix_response</th>\n",
       "      <th>grade</th>\n",
       "      <th>feedbackimageurl</th>\n",
       "      <th>...</th>\n",
       "      <th>infographics_value</th>\n",
       "      <th>infographics_confidence</th>\n",
       "      <th>topic_value</th>\n",
       "      <th>topic_confidence</th>\n",
       "      <th>regr_data_type</th>\n",
       "      <th>section_v2_value</th>\n",
       "      <th>section_v2_confidence</th>\n",
       "      <th>infographics_v2_value</th>\n",
       "      <th>infographics_v2_confidence</th>\n",
       "      <th>rn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00004d3f-c0e7-406e-adbd-4629e318c1a1</td>\n",
       "      <td>M3190541E001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-01-20 14:01:28.17445</td>\n",
       "      <td>exact</td>\n",
       "      <td>{\"tags\": [], \"searchId\": \"\", \"searchImageUrl\":...</td>\n",
       "      <td>https://coln-prd-sg-s3-ads-pub.s3.ap-southeast...</td>\n",
       "      <td>{\"request_id\": \"cb71c470a45db5eb9d419e079274f8...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>https://msd-iq.s3-ap-southeast-1.amazonaws.com...</td>\n",
       "      <td>...</td>\n",
       "      <td>no_infographics</td>\n",
       "      <td>1.00</td>\n",
       "      <td>ruang sampel</td>\n",
       "      <td>0.6</td>\n",
       "      <td>positive</td>\n",
       "      <td>probability</td>\n",
       "      <td>0.94</td>\n",
       "      <td>no_infographics</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00004d3f-c0e7-406e-adbd-4629e318c1a1</td>\n",
       "      <td>M0251861P002</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-10-16 14:01:36.579959</td>\n",
       "      <td>exact</td>\n",
       "      <td>{\"tags\": [], \"searchId\": \"\", \"searchImageUrl\":...</td>\n",
       "      <td>https://coln-prd-sg-s3-ads-pub.s3.ap-southeast...</td>\n",
       "      <td>{\"request_id\": \"cb71c470a45db5eb9d419e079274f8...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>https://msd-iq.s3-ap-southeast-1.amazonaws.com...</td>\n",
       "      <td>...</td>\n",
       "      <td>no_infographics</td>\n",
       "      <td>1.00</td>\n",
       "      <td>ruang sampel</td>\n",
       "      <td>0.6</td>\n",
       "      <td>positive</td>\n",
       "      <td>probability</td>\n",
       "      <td>0.94</td>\n",
       "      <td>no_infographics</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00004d3f-c0e7-406e-adbd-4629e318c1a1</td>\n",
       "      <td>M1350532E019</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-08-22 02:01:45.250414</td>\n",
       "      <td>exact</td>\n",
       "      <td>{\"tags\": [], \"searchId\": \"\", \"searchImageUrl\":...</td>\n",
       "      <td>https://coln-prd-sg-s3-ads-pub.s3.ap-southeast...</td>\n",
       "      <td>{\"request_id\": \"cb71c470a45db5eb9d419e079274f8...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>https://msd-iq.s3-ap-southeast-1.amazonaws.com...</td>\n",
       "      <td>...</td>\n",
       "      <td>no_infographics</td>\n",
       "      <td>1.00</td>\n",
       "      <td>ruang sampel</td>\n",
       "      <td>0.6</td>\n",
       "      <td>positive</td>\n",
       "      <td>probability</td>\n",
       "      <td>0.94</td>\n",
       "      <td>no_infographics</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00004d3f-c0e7-406e-adbd-4629e318c1a1</td>\n",
       "      <td>M1591111P001</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2021-05-20 14:01:51.214624</td>\n",
       "      <td>exact</td>\n",
       "      <td>{\"tags\": [], \"searchId\": \"\", \"searchImageUrl\":...</td>\n",
       "      <td>https://coln-prd-sg-s3-ads-pub.s3.ap-southeast...</td>\n",
       "      <td>{\"request_id\": \"cb71c470a45db5eb9d419e079274f8...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>https://msd-iq.s3-ap-southeast-1.amazonaws.com...</td>\n",
       "      <td>...</td>\n",
       "      <td>no_infographics</td>\n",
       "      <td>1.00</td>\n",
       "      <td>ruang sampel</td>\n",
       "      <td>0.6</td>\n",
       "      <td>positive</td>\n",
       "      <td>probability</td>\n",
       "      <td>0.94</td>\n",
       "      <td>no_infographics</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000050b6-21d3-41d8-b51c-ba712add7962</td>\n",
       "      <td>M2502031E002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-11-28 02:01:20.181711</td>\n",
       "      <td>exact</td>\n",
       "      <td>{\"tags\": [], \"searchId\": \"\", \"searchImageUrl\":...</td>\n",
       "      <td>https://coln-prd-sg-s3-ads-pub.s3.ap-southeast...</td>\n",
       "      <td>{\"request_id\": \"c70363000ab00da3b7031de502eb17...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>https://msd-iq.s3-ap-southeast-1.amazonaws.com...</td>\n",
       "      <td>...</td>\n",
       "      <td>cube/cuboid</td>\n",
       "      <td>0.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "      <td>geometry</td>\n",
       "      <td>0.60</td>\n",
       "      <td>no_infographics</td>\n",
       "      <td>0.68</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             request_id   question_id  index  \\\n",
       "0  00004d3f-c0e7-406e-adbd-4629e318c1a1  M3190541E001    0.0   \n",
       "1  00004d3f-c0e7-406e-adbd-4629e318c1a1  M0251861P002    3.0   \n",
       "2  00004d3f-c0e7-406e-adbd-4629e318c1a1  M1350532E019    4.0   \n",
       "3  00004d3f-c0e7-406e-adbd-4629e318c1a1  M1591111P001    7.0   \n",
       "4  000050b6-21d3-41d8-b51c-ba712add7962  M2502031E002    0.0   \n",
       "\n",
       "                   created_at feedback  \\\n",
       "0   2021-01-20 14:01:28.17445    exact   \n",
       "1  2020-10-16 14:01:36.579959    exact   \n",
       "2  2020-08-22 02:01:45.250414    exact   \n",
       "3  2021-05-20 14:01:51.214624    exact   \n",
       "4  2020-11-28 02:01:20.181711    exact   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {\"tags\": [], \"searchId\": \"\", \"searchImageUrl\":...   \n",
       "1  {\"tags\": [], \"searchId\": \"\", \"searchImageUrl\":...   \n",
       "2  {\"tags\": [], \"searchId\": \"\", \"searchImageUrl\":...   \n",
       "3  {\"tags\": [], \"searchId\": \"\", \"searchImageUrl\":...   \n",
       "4  {\"tags\": [], \"searchId\": \"\", \"searchImageUrl\":...   \n",
       "\n",
       "                                      searchimageurl  \\\n",
       "0  https://coln-prd-sg-s3-ads-pub.s3.ap-southeast...   \n",
       "1  https://coln-prd-sg-s3-ads-pub.s3.ap-southeast...   \n",
       "2  https://coln-prd-sg-s3-ads-pub.s3.ap-southeast...   \n",
       "3  https://coln-prd-sg-s3-ads-pub.s3.ap-southeast...   \n",
       "4  https://coln-prd-sg-s3-ads-pub.s3.ap-southeast...   \n",
       "\n",
       "                                    mathpix_response  grade  \\\n",
       "0  {\"request_id\": \"cb71c470a45db5eb9d419e079274f8...    8.0   \n",
       "1  {\"request_id\": \"cb71c470a45db5eb9d419e079274f8...    8.0   \n",
       "2  {\"request_id\": \"cb71c470a45db5eb9d419e079274f8...    8.0   \n",
       "3  {\"request_id\": \"cb71c470a45db5eb9d419e079274f8...    8.0   \n",
       "4  {\"request_id\": \"c70363000ab00da3b7031de502eb17...    8.0   \n",
       "\n",
       "                                    feedbackimageurl  ... infographics_value  \\\n",
       "0  https://msd-iq.s3-ap-southeast-1.amazonaws.com...  ...    no_infographics   \n",
       "1  https://msd-iq.s3-ap-southeast-1.amazonaws.com...  ...    no_infographics   \n",
       "2  https://msd-iq.s3-ap-southeast-1.amazonaws.com...  ...    no_infographics   \n",
       "3  https://msd-iq.s3-ap-southeast-1.amazonaws.com...  ...    no_infographics   \n",
       "4  https://msd-iq.s3-ap-southeast-1.amazonaws.com...  ...        cube/cuboid   \n",
       "\n",
       "  infographics_confidence   topic_value  topic_confidence regr_data_type  \\\n",
       "0                    1.00  ruang sampel               0.6       positive   \n",
       "1                    1.00  ruang sampel               0.6       positive   \n",
       "2                    1.00  ruang sampel               0.6       positive   \n",
       "3                    1.00  ruang sampel               0.6       positive   \n",
       "4                    0.82           NaN               NaN       positive   \n",
       "\n",
       "   section_v2_value section_v2_confidence  infographics_v2_value  \\\n",
       "0       probability                  0.94        no_infographics   \n",
       "1       probability                  0.94        no_infographics   \n",
       "2       probability                  0.94        no_infographics   \n",
       "3       probability                  0.94        no_infographics   \n",
       "4          geometry                  0.60        no_infographics   \n",
       "\n",
       "  infographics_v2_confidence  rn  \n",
       "0                       1.00 NaN  \n",
       "1                       1.00 NaN  \n",
       "2                       1.00 NaN  \n",
       "3                       1.00 NaN  \n",
       "4                       0.68 NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "768e7517-8aeb-40e1-a919-8547c3618817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"tags\": [], \"searchId\": \"\", \"searchImageUrl\": \"https://coln-prd-sg-s3-ads-pub.s3.ap-southeast-1.amazonaws.com/images/search-questions/b0de1941-1c97-481b-80ec-6c0aa56f3463\", \"feedbackImageUrl\": \"\", \"comment\": \"\", \"image_type\": [\"More than one question in one image\"], \"picture_taken\": \"Screenshot\", \"subject\": [\"maths\"], \"section\": [\"STATISTIKA\"], \"chapter\": [\"PELUANG\"], \"topic\": [\"Ruang Sampel\"], \"flagged\": false, \"sample_type\": \"D0_\"}___1,{\"tags\": [], \"searchId\": \"\", \"searchImageUrl\": \"https://coln-prd-sg-s3-ads-pub.s3.ap-southeast-1.amazonaws.com/images/search-questions/b0de1941-1c97-481b-80ec-6c0aa56f3463\", \"feedbackImageUrl\": \"\", \"comment\": \"\", \"image_type\": [\"More than one question in one image\"], \"picture_taken\": \"Screenshot\", \"subject\": [\"maths\"], \"section\": [\"STATISTIKA\"], \"chapter\": [\"PELUANG\"], \"topic\": [\"Ruang Sampel\"], \"flagged\": false, \"sample_type\": \"D0_\"}___2'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list.loc[0,'metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "375562ae-4e6f-4cfb-ba1b-b51074700d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "request_id                                 00004d3f-c0e7-406e-adbd-4629e318c1a1\n",
       "question_id                                                        M3190541E001\n",
       "index                                                                       0.0\n",
       "created_at                                            2021-01-20 14:01:28.17445\n",
       "feedback                                                                  exact\n",
       "metadata                      {\"tags\": [], \"searchId\": \"\", \"searchImageUrl\":...\n",
       "searchimageurl                https://coln-prd-sg-s3-ads-pub.s3.ap-southeast...\n",
       "mathpix_response              {\"request_id\": \"cb71c470a45db5eb9d419e079274f8...\n",
       "grade                                                                       8.0\n",
       "feedbackimageurl              https://msd-iq.s3-ap-southeast-1.amazonaws.com...\n",
       "feedback_image_text           Sebuah dadu dan sebuah uang logam dilemparkan ...\n",
       "created_date                                                2021-05-27 22:49:32\n",
       "subject_value                                                             maths\n",
       "subject_confidence                                                         0.88\n",
       "section_value                                                        statistika\n",
       "section_confidence                                                         0.79\n",
       "chapter_value                                                           peluang\n",
       "chapter_confidence                                                         0.66\n",
       "infographics_value                                              no_infographics\n",
       "infographics_confidence                                                     1.0\n",
       "topic_value                                                        ruang sampel\n",
       "topic_confidence                                                            0.6\n",
       "regr_data_type                                                         positive\n",
       "section_v2_value                                                    probability\n",
       "section_v2_confidence                                                      0.94\n",
       "infographics_v2_value                                           no_infographics\n",
       "infographics_v2_confidence                                                  1.0\n",
       "rn                                                                          NaN\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list.loc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "16835874-dfd1-413e-90f3-e5b9c3fdefdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"request_id\": \"cb71c470a45db5eb9d419e079274f893\", \"detected_alphabets\": {\"hi\": false, \"zh\": false, \"ja\": false, \"ko\": false, \"en\": true, \"ru\": false, \"th\": false}, \"is_printed\": true, \"is_handwritten\": false, \"auto_rotate_confidence\": 0.00020815567736676144, \"auto_rotate_degrees\": 0, \"confidence\": 0.2724175613547004, \"confidence_rate\": 0.7061789593565754, \"text\": \"2\\\\n)\\\\nSebuah mata uang di lempar, maka himpunan ruang sampelnya adalah....\\\\nA. \\\\\\\\{angka\\\\\\\\}\\\\nC. \\\\\\\\{gambar, angka\\\\\\\\}\\\\nB. \\\\\\\\{gambar\\\\\\\\}\\\\nD. 11\\\\nDua buah dadu logam di lempar bersama-sama. Banyaknya titik sampel adalah....\\\\nA. 36\\\\nB. 12\\\\nC. 8\\\\nD. 6\", \"html\": \"<div>2<br>\\\\n)<br>\\\\nSebuah mata uang di lempar, maka himpunan ruang sampelnya adalah....<br>\\\\nA. {angka}<br>\\\\nC. {gambar, angka}<br>\\\\nB. {gambar}<br>\\\\nD. 11<br>\\\\nDua buah dadu logam di lempar bersama-sama. Banyaknya titik sampel adalah....<br>\\\\nA. 36<br>\\\\nB. 12<br>\\\\nC. 8<br>\\\\nD. 6</div>\\\\n\", \"data\": []}'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list.loc[0,'mathpix_response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "78261be1-c66e-48db-8a67-f0e26ba15e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 179052: unexpected end of data\n"
     ]
    }
   ],
   "source": [
    "df_index_data = pd.read_csv('indexData.csv', sep=',', engine='python', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9f1b5fee-e820-433c-a409-98ede9b88591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['question_id', 's3_path', 'mathpix_response', 'created_at', 'extras',\n",
       "       'subject', 'rn', 'image_url', 'question_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_index_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d7ccaa87-05a6-4687-9c6c-6a506e41fb78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>s3_path</th>\n",
       "      <th>mathpix_response</th>\n",
       "      <th>created_at</th>\n",
       "      <th>extras</th>\n",
       "      <th>subject</th>\n",
       "      <th>rn</th>\n",
       "      <th>image_url</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0010103P003</td>\n",
       "      <td>s3://msd-iq/client_images/2020-11-07 02:01:15....</td>\n",
       "      <td>{\"request_id\": \"c16f527231a2bfa1e016bff8ec6d7f...</td>\n",
       "      <td>2020-11-07 02:01:15.947613</td>\n",
       "      <td>{\"source\": {\"websiteDetails\": {\"grade\": null, ...</td>\n",
       "      <td>[\"maths\"]</td>\n",
       "      <td>1</td>\n",
       "      <td>https://msd-iq.s3-ap-southeast-1.amazonaws.com...</td>\n",
       "      <td>Diketahui \\\\( \\\\mathrm{X}=\\\\{\\\\mathrm{x} \\\\mid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0010103P004</td>\n",
       "      <td>s3://msd-iq/client_images/2021-05-20 14:01:51....</td>\n",
       "      <td>{\"request_id\": \"cbdd9656a6aa0b29cef0fb3e303ab9...</td>\n",
       "      <td>2021-05-20 14:01:51.214624</td>\n",
       "      <td>{\"description\": \"\", \"tags\": {\"primaryTopic\": {...</td>\n",
       "      <td>[\"maths\"]</td>\n",
       "      <td>1</td>\n",
       "      <td>https://msd-iq.s3-ap-southeast-1.amazonaws.com...</td>\n",
       "      <td>Jika \\\\( \\\\mathrm{n}(\\\\mathrm{A})=10, \\\\mathrm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0010109P001</td>\n",
       "      <td>s3://msd-iq/client_images/2021-05-20 14:01:51....</td>\n",
       "      <td>{\"request_id\": \"ae6403766208ebf0234b5b7c693e42...</td>\n",
       "      <td>2021-05-20 14:01:51.214624</td>\n",
       "      <td>{\"description\": \"\", \"tags\": {\"primaryTopic\": {...</td>\n",
       "      <td>[\"maths\"]</td>\n",
       "      <td>1</td>\n",
       "      <td>https://msd-iq.s3-ap-southeast-1.amazonaws.com...</td>\n",
       "      <td>Perhatikan persamaan-persamaan berikut !\\n(i) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0010109P002</td>\n",
       "      <td>s3://msd-iq/client_images/2021-05-20 14:01:51....</td>\n",
       "      <td>{\"request_id\": \"e05e1b73bfc8c070d099d9becb65c5...</td>\n",
       "      <td>2021-05-20 14:01:51.214624</td>\n",
       "      <td>{\"description\": \"\", \"tags\": {\"primaryTopic\": {...</td>\n",
       "      <td>[\"maths\"]</td>\n",
       "      <td>1</td>\n",
       "      <td>https://msd-iq.s3-ap-southeast-1.amazonaws.com...</td>\n",
       "      <td>Perhatikan persamaan-persamaan berikut !\\n(i) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0010109P003</td>\n",
       "      <td>s3://msd-iq/client_images/2020-11-06 02:01:18....</td>\n",
       "      <td>{\"request_id\": \"03ed91e0ba125482fec03cfd21d029...</td>\n",
       "      <td>2020-11-06 02:01:18.015423</td>\n",
       "      <td>{\"source\": {\"websiteDetails\": {\"grade\": null, ...</td>\n",
       "      <td>[\"maths\"]</td>\n",
       "      <td>1</td>\n",
       "      <td>https://msd-iq.s3-ap-southeast-1.amazonaws.com...</td>\n",
       "      <td>Rina membeli 3 kg apel dan 2 kg jeruk. Uang ya...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    question_id                                            s3_path  \\\n",
       "0  A0010103P003  s3://msd-iq/client_images/2020-11-07 02:01:15....   \n",
       "1  A0010103P004  s3://msd-iq/client_images/2021-05-20 14:01:51....   \n",
       "2  A0010109P001  s3://msd-iq/client_images/2021-05-20 14:01:51....   \n",
       "3  A0010109P002  s3://msd-iq/client_images/2021-05-20 14:01:51....   \n",
       "4  A0010109P003  s3://msd-iq/client_images/2020-11-06 02:01:18....   \n",
       "\n",
       "                                    mathpix_response  \\\n",
       "0  {\"request_id\": \"c16f527231a2bfa1e016bff8ec6d7f...   \n",
       "1  {\"request_id\": \"cbdd9656a6aa0b29cef0fb3e303ab9...   \n",
       "2  {\"request_id\": \"ae6403766208ebf0234b5b7c693e42...   \n",
       "3  {\"request_id\": \"e05e1b73bfc8c070d099d9becb65c5...   \n",
       "4  {\"request_id\": \"03ed91e0ba125482fec03cfd21d029...   \n",
       "\n",
       "                   created_at  \\\n",
       "0  2020-11-07 02:01:15.947613   \n",
       "1  2021-05-20 14:01:51.214624   \n",
       "2  2021-05-20 14:01:51.214624   \n",
       "3  2021-05-20 14:01:51.214624   \n",
       "4  2020-11-06 02:01:18.015423   \n",
       "\n",
       "                                              extras    subject  rn  \\\n",
       "0  {\"source\": {\"websiteDetails\": {\"grade\": null, ...  [\"maths\"]   1   \n",
       "1  {\"description\": \"\", \"tags\": {\"primaryTopic\": {...  [\"maths\"]   1   \n",
       "2  {\"description\": \"\", \"tags\": {\"primaryTopic\": {...  [\"maths\"]   1   \n",
       "3  {\"description\": \"\", \"tags\": {\"primaryTopic\": {...  [\"maths\"]   1   \n",
       "4  {\"source\": {\"websiteDetails\": {\"grade\": null, ...  [\"maths\"]   1   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://msd-iq.s3-ap-southeast-1.amazonaws.com...   \n",
       "1  https://msd-iq.s3-ap-southeast-1.amazonaws.com...   \n",
       "2  https://msd-iq.s3-ap-southeast-1.amazonaws.com...   \n",
       "3  https://msd-iq.s3-ap-southeast-1.amazonaws.com...   \n",
       "4  https://msd-iq.s3-ap-southeast-1.amazonaws.com...   \n",
       "\n",
       "                                       question_text  \n",
       "0  Diketahui \\\\( \\\\mathrm{X}=\\\\{\\\\mathrm{x} \\\\mid...  \n",
       "1  Jika \\\\( \\\\mathrm{n}(\\\\mathrm{A})=10, \\\\mathrm...  \n",
       "2  Perhatikan persamaan-persamaan berikut !\\n(i) ...  \n",
       "3  Perhatikan persamaan-persamaan berikut !\\n(i) ...  \n",
       "4  Rina membeli 3 kg apel dan 2 kg jeruk. Uang ya...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_index_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "200d5443-4315-4bc6-a3b6-68c0ebf9f2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179050"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_index_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "33752f9a-2e11-4eb2-8b3c-5f2b6567820d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"source\": {\"websiteDetails\": {\"grade\": null, \"curriculum\": null, \"publication\": \"www.juraganles.com\", \"title\": \"Matematika Juragan Les\"}, \"type\": \"Website\"}, \"description\": \"\", \"timestamp\": 1616997407079, \"tags\": {\"chapter\": [\"HIMPUNAN\"], \"questionType\": [\"Uncategorized\"], \"section\": [\"ALJABAR\"], \"difficultyLevel\": \"D1\", \"imageInQuestion\": false, \"primaryTopic\": {\"grade\": \"7\", \"topicId\": \"07AN20207\", \"semester\": \"1\", \"streamType\": \"SMP\"}, \"topic\": [\"Operasi Himpunan\"], \"bloomsTaxonomy\": [\"C3 Aplikasi\"], \"subject\": [\"Maths\"]}}'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_index_data.loc[0,'extras']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fc9f476d-31ed-42f3-ba27-e3ff988170c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9dbe6e846954acd9ad8c1e1acc98393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/230k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccff0be53607441caccae449645ec396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01eaa15dd46847319ee3cdcc77eea735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/62.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50ca7c03c024299afd0e2ee5d8dbb8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/468 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c08bf7d7d2834c0c8f3d36b3841011e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/545M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at cahya/bert-base-indonesian-522M were not used when initializing TFBertModel: ['mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at cahya/bert-base-indonesian-522M.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "model_name='cahya/bert-base-indonesian-522M'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = TFBertModel.from_pretrained(model_name)\n",
    "text = \"Silakan diganti dengan text apa saja.\"\n",
    "encoded_input = tokenizer(text, return_tensors='tf')\n",
    "output = model(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ea9ca2b7-fbba-4696-ac99-35a43c3570df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFBaseModelOutputWithPooling(last_hidden_state=<tf.Tensor: shape=(1, 10, 768), dtype=float32, numpy=\n",
       "array([[[-0.07926931, -0.41667727,  0.01540737, ...,  0.322052  ,\n",
       "         -0.47354588, -0.7253795 ],\n",
       "        [ 0.0719403 , -0.4571825 ,  0.8287917 , ...,  0.29290366,\n",
       "         -1.1612344 ,  0.3168729 ],\n",
       "        [-0.15491223, -0.94698083,  0.3294129 , ...,  1.2914243 ,\n",
       "         -1.4274261 ,  0.27289003],\n",
       "        ...,\n",
       "        [-2.4184837 ,  0.13898858,  0.6879961 , ...,  2.126189  ,\n",
       "          0.05418604,  0.00736356],\n",
       "        [ 0.04243735,  0.31144488,  0.42113376, ...,  0.51701397,\n",
       "          0.47521394, -0.764553  ],\n",
       "        [-0.26480502,  0.497233  , -0.89467394, ...,  0.9380146 ,\n",
       "         -0.48444355, -1.0249774 ]]], dtype=float32)>, pooler_output=<tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
       "array([[-0.19222063, -0.5219983 , -0.8855573 , -0.13142143, -0.26546386,\n",
       "         0.56655884,  0.13956298, -0.3470618 ,  0.4399549 ,  0.03775845,\n",
       "        -0.05163716,  0.28938904,  0.666814  ,  0.26101026,  0.19967678,\n",
       "         0.35161436,  0.13680077, -0.7667022 , -0.588407  , -0.6019403 ,\n",
       "         0.31033137,  0.72608656, -0.05938045,  0.41732717,  0.2542333 ,\n",
       "        -0.13390759,  0.46605122, -0.06585091,  0.19475976,  0.26848266,\n",
       "         0.57411355,  0.05012896,  0.04762117, -0.57002085,  0.15278724,\n",
       "        -0.6514794 , -0.36864504, -0.8268244 ,  0.8507695 ,  0.5001741 ,\n",
       "         0.5736133 , -0.67721343, -0.36933225,  0.37415802, -0.4498714 ,\n",
       "        -0.68218166, -0.54204714, -0.09856119,  0.73468214, -0.24947463,\n",
       "         0.69776595, -0.0654927 , -0.8968053 ,  0.2816453 ,  0.7766375 ,\n",
       "         0.57119447,  0.3963403 ,  0.33556437, -0.14562209,  0.5899297 ,\n",
       "        -0.25890306,  0.16746087,  0.6822983 ,  0.09549905, -0.02564619,\n",
       "         0.09500415, -0.38068345,  0.46681485, -0.02844369,  0.07732901,\n",
       "        -0.46418294, -0.21310592, -0.13512726, -0.3769155 , -0.20974876,\n",
       "        -0.20832597,  0.24000578, -0.21380155,  0.7315743 , -0.09141716,\n",
       "        -0.08870672, -0.03788557,  0.0885203 ,  0.01225789,  0.11617675,\n",
       "         0.8059379 , -0.5971755 , -0.5590162 , -0.15498814, -0.17692828,\n",
       "         0.48337543,  0.33140963, -0.5351318 ,  0.00390882,  0.08318536,\n",
       "        -0.7179925 , -0.26875615,  0.5852454 ,  0.48586822, -0.44355828,\n",
       "         0.6937125 , -0.21435037, -0.39372042, -0.01982797, -0.08174393,\n",
       "         0.20863149,  0.58718103,  0.61307913, -0.36988118, -0.04594022,\n",
       "         0.08142103, -0.01163463, -0.8990245 ,  0.39196578,  0.25061667,\n",
       "        -0.3720509 ,  0.33490336, -0.09114192, -0.0937204 ,  0.0686748 ,\n",
       "        -0.42748216,  0.22675045,  0.25996226, -0.38563642,  0.40430364,\n",
       "         0.76771766,  0.5626413 ,  0.36267325, -0.4795827 ,  0.88930357,\n",
       "        -0.23549736, -0.18689695,  0.34803796,  0.20852944, -0.548876  ,\n",
       "        -0.04621364, -0.1265832 ,  0.33326334, -0.7050552 , -0.31770784,\n",
       "         0.6285772 ,  0.2587606 ,  0.6560197 , -0.5737355 ,  0.20540135,\n",
       "        -0.41585281,  0.23036636, -0.12709253,  0.41330898,  0.06942676,\n",
       "         0.2523747 , -0.5893951 , -0.28409082, -0.41795173, -0.79799926,\n",
       "         0.70449793, -0.52058136,  0.20100847, -0.23116848, -0.8375542 ,\n",
       "        -0.11882931, -0.03977003, -0.4315604 , -0.46717885, -0.01070438,\n",
       "         0.02751069, -0.451542  ,  0.3000345 , -0.64096487,  0.6315512 ,\n",
       "         0.4456406 , -0.5883394 , -0.11602682, -0.74474984, -0.673925  ,\n",
       "        -0.47479016,  0.20109381,  0.47540542, -0.60631907,  0.432445  ,\n",
       "        -0.25191593, -0.21135186, -0.05769062,  0.11829055, -0.46303567,\n",
       "        -0.49839473, -0.21618535,  0.31796136,  0.28018185,  0.5878798 ,\n",
       "        -0.14596783, -0.47549883, -0.759812  , -0.26517615,  0.05177079,\n",
       "        -0.32391992, -0.22005522,  0.12229027, -0.5827385 ,  0.14001797,\n",
       "         0.20525806,  0.5409048 , -0.4428425 ,  0.39115432,  0.01784837,\n",
       "        -0.48144352,  0.5332205 , -0.76661426,  0.25736296,  0.2393379 ,\n",
       "        -0.23977055,  0.24215096, -0.8469531 ,  0.40118647, -0.42991248,\n",
       "         0.34224078,  0.4074573 , -0.5643208 ,  0.60723406, -0.61273634,\n",
       "         0.25259146,  0.37244886,  0.1054852 ,  0.18349032, -0.64476323,\n",
       "         0.87532175,  0.043653  ,  0.59513205, -0.6604128 , -0.26094338,\n",
       "        -0.48155907,  0.7308019 ,  0.32496393, -0.6766197 ,  0.33479148,\n",
       "         0.6754176 , -0.39938575, -0.24000458,  0.14837506,  0.24093933,\n",
       "        -0.3092575 ,  0.665949  , -0.73371977,  0.81271166, -0.35363844,\n",
       "        -0.6064049 ,  0.58827937,  0.49422228, -0.66081536,  0.3058524 ,\n",
       "         0.02613535,  0.2223152 ,  0.03308112,  0.69186276,  0.13513799,\n",
       "        -0.43443134, -0.12675093, -0.565992  ,  0.5498327 , -0.52185297,\n",
       "         0.0197068 , -0.6425384 , -0.5314471 , -0.5418993 ,  0.26077285,\n",
       "         0.02423518, -0.044656  , -0.00768554,  0.5209386 ,  0.48384616,\n",
       "         0.15877262, -0.26106253, -0.6606156 , -0.44615257, -0.22967681,\n",
       "         0.566959  , -0.19624709,  0.167035  , -0.41086626,  0.48033094,\n",
       "         0.2960546 ,  0.03767955,  0.03027941,  0.42687234, -0.62676835,\n",
       "         0.33478752, -0.20018092, -0.25237888,  0.41812834,  0.34659117,\n",
       "        -0.1314591 , -0.78437424, -0.5258547 , -0.8123476 , -0.41669834,\n",
       "        -0.4210358 , -0.69564474, -0.6122145 ,  0.22594582,  0.25186285,\n",
       "        -0.34345263,  0.05929788,  0.1590733 ,  0.7678793 ,  0.02484156,\n",
       "         0.12975122,  0.11342048,  0.3955112 ,  0.67615783, -0.6333622 ,\n",
       "        -0.05092194,  0.7413869 , -0.14896722, -0.8577508 ,  0.35515252,\n",
       "        -0.11582063, -0.4083489 , -0.37498316,  0.02923415,  0.16591077,\n",
       "         0.11070437, -0.1001533 ,  0.758253  , -0.2974891 , -0.36646992,\n",
       "        -0.38208345, -0.4602658 ,  0.08784466, -0.51498663,  0.0834253 ,\n",
       "        -0.29785544, -0.01159322, -0.24867636, -0.41110584,  0.43676668,\n",
       "         0.11835069,  0.40675735,  0.5723057 ,  0.10204607,  0.55337965,\n",
       "         0.6884438 , -0.4465126 ,  0.62022585, -0.18942742, -0.10909343,\n",
       "        -0.45092332,  0.456208  , -0.51642627, -0.40227965, -0.1353587 ,\n",
       "         0.21332808,  0.56130034,  0.2170601 , -0.5923952 ,  0.32581028,\n",
       "        -0.17317598,  0.02005037, -0.19206123,  0.04649307,  0.7842384 ,\n",
       "        -0.61960834, -0.73981816, -0.03333057, -0.21240793,  0.34405854,\n",
       "        -0.21119934,  0.64663035,  0.34565866, -0.6466248 ,  0.6610643 ,\n",
       "        -0.47052112, -0.36870763,  0.24373841, -0.05197079,  0.03392612,\n",
       "         0.56547654, -0.20717356, -0.31208044, -0.45225412, -0.5501918 ,\n",
       "        -0.5265023 , -0.1643678 , -0.12885399, -0.07075156,  0.1424614 ,\n",
       "         0.47315213, -0.5992353 ,  0.12194865, -0.55620956, -0.5273341 ,\n",
       "         0.22255659,  0.36579183, -0.40468082, -0.664149  ,  0.68560445,\n",
       "         0.48882386, -0.00898417,  0.13311106,  0.37293616,  0.07048754,\n",
       "        -0.06887324,  0.73984885,  0.44635415, -0.23039107, -0.5218707 ,\n",
       "        -0.16995434,  0.32845473, -0.64058805,  0.15606175, -0.5646443 ,\n",
       "         0.08789384, -0.6533529 , -0.37529203, -0.49513328,  0.0607692 ,\n",
       "        -0.7262167 ,  0.1005673 , -0.12236336,  0.666226  , -0.78132606,\n",
       "        -0.02658235,  0.54530466,  0.4933752 , -0.31515697, -0.31965926,\n",
       "        -0.7698938 ,  0.50256866,  0.33238983, -0.42337182,  0.3595384 ,\n",
       "         0.8215346 ,  0.40026286,  0.28693533, -0.457912  , -0.15553597,\n",
       "        -0.54841584, -0.7334466 , -0.10162247, -0.04534696,  0.35201266,\n",
       "         0.35331658, -0.09925997, -0.49984518, -0.670293  ,  0.5547343 ,\n",
       "         0.6310623 ,  0.30079383, -0.20965672,  0.10721467, -0.6405963 ,\n",
       "         0.9587567 ,  0.71054447,  0.06082341, -0.2389657 ,  0.8079638 ,\n",
       "         0.5368264 , -0.06514037,  0.25643727,  0.29738843,  0.97496724,\n",
       "         0.06534308, -0.07415077,  0.11415555,  0.138524  , -0.19741787,\n",
       "        -0.06775052, -0.15190902, -0.31528524,  0.5123292 ,  0.4781634 ,\n",
       "         0.09043828,  0.5312746 , -0.05164566, -0.52420175, -0.21031962,\n",
       "         0.06144171, -0.27838543, -0.28762558,  0.27590623, -0.44784606,\n",
       "         0.75722945, -0.11787374,  0.01900717, -0.29661706,  0.29012033,\n",
       "        -0.45762563,  0.36789462,  0.4888464 , -0.22834668, -0.6625764 ,\n",
       "        -0.05930248,  0.2211828 ,  0.1269957 , -0.04085107, -0.51343805,\n",
       "        -0.12455934,  0.20936653, -0.40275124, -0.5909574 , -0.05036965,\n",
       "         0.4816895 , -0.69029856,  0.01296951, -0.14676584, -0.21958497,\n",
       "        -0.8261517 , -0.51832134, -0.31643364,  0.1483954 , -0.24696738,\n",
       "         0.12883829,  0.42848694, -0.6052406 ,  0.16231953,  0.8818773 ,\n",
       "         0.5307779 , -0.36676472, -0.36871454,  0.22658816,  0.44026178,\n",
       "         0.2644379 , -0.09283383,  0.14495283,  0.31062043, -0.15951383,\n",
       "        -0.7546557 ,  0.52327585,  0.93381363,  0.0711154 , -0.11265466,\n",
       "        -0.48747075,  0.46974182, -0.6412482 , -0.47323763, -0.12792143,\n",
       "        -0.014803  ,  0.58399034, -0.46282983,  0.26278272, -0.14085148,\n",
       "         0.3773389 , -0.15459079, -0.62708294,  0.13334255, -0.29016903,\n",
       "        -0.5535905 , -0.06456868, -0.27319035,  0.45181113,  0.24261905,\n",
       "         0.32214367,  0.1067057 , -0.8165487 ,  0.12096675, -0.22979964,\n",
       "        -0.28558993, -0.5067496 , -0.7341633 ,  0.08041155,  0.37055287,\n",
       "         0.6601492 , -0.6288097 , -0.51091975, -0.6361404 ,  0.5655841 ,\n",
       "        -0.0130238 ,  0.22545782,  0.5214576 ,  0.2571894 ,  0.7172088 ,\n",
       "         0.6780767 , -0.5650101 , -0.64868   ,  0.5509864 ,  0.59946895,\n",
       "         0.5130177 ,  0.32974535,  0.8018514 , -0.40922686,  0.06179257,\n",
       "         0.1332811 ,  0.4834874 ,  0.4722814 ,  0.3934977 ,  0.73152065,\n",
       "         0.52402097,  0.5358358 , -0.35346437,  0.14905109,  0.60024834,\n",
       "        -0.1915966 , -0.6848397 ,  0.6156427 ,  0.09219544, -0.33955848,\n",
       "         0.3715414 ,  0.45690644, -0.85405725, -0.5406324 , -0.3515244 ,\n",
       "        -0.58215266,  0.4730284 ,  0.04451797, -0.23366748,  0.05929556,\n",
       "         0.6907666 ,  0.5725175 ,  0.27787367,  0.60026217, -0.13891353,\n",
       "        -0.44970566, -0.08238951,  0.365407  , -0.4917036 ,  0.56651074,\n",
       "         0.10445742,  0.3871013 ,  0.71569526,  0.17230459,  0.64321744,\n",
       "        -0.15721327,  0.7231652 ,  0.02378121, -0.06462798, -0.28944197,\n",
       "        -0.00268077,  0.4439247 , -0.11393245, -0.5879399 , -0.21031754,\n",
       "         0.42612213,  0.02868269, -0.7805618 ,  0.18890913,  0.647833  ,\n",
       "         0.70540667, -0.65766215,  0.7180319 ,  0.8222689 ,  0.2304387 ,\n",
       "        -0.3791143 ,  0.12962404,  0.17384243,  0.23718865, -0.23117544,\n",
       "         0.03248165, -0.54106677, -0.46703407,  0.2256857 , -0.06532666,\n",
       "         0.44317213,  0.5160388 , -0.53074336,  0.03491114, -0.54447156,\n",
       "         0.00140181,  0.28634468, -0.4786143 ,  0.13446146,  0.0098242 ,\n",
       "         0.8288444 , -0.12184761, -0.54460055, -0.48514944, -0.21204467,\n",
       "         0.7245414 ,  0.12268968,  0.4464164 ,  0.48748678, -0.5067125 ,\n",
       "        -0.18032417, -0.7800122 , -0.5767745 ,  0.60830843, -0.10958974,\n",
       "        -0.24443665,  0.18087552,  0.79643416, -0.4671701 , -0.32144567,\n",
       "         0.01577719,  0.06807093, -0.3392537 ,  0.4405147 , -0.48204356,\n",
       "        -0.1097239 , -0.01810274, -0.9128599 ,  0.13207063,  0.43441382,\n",
       "        -0.64606655, -0.7467363 , -0.45108864, -0.7380399 ,  0.5032121 ,\n",
       "         0.6541118 , -0.45734704,  0.7787256 ,  0.37398466,  0.6826448 ,\n",
       "         0.42127734, -0.03792858,  0.02625921, -0.30821076, -0.3123661 ,\n",
       "         0.03262169,  0.18813194, -0.37726513,  0.17053206, -0.33433095,\n",
       "         0.16265282, -0.3463227 ,  0.01549594,  0.3358292 ,  0.0992866 ,\n",
       "         0.56441694,  0.09042694,  0.5134166 , -0.24691917,  0.37003636,\n",
       "        -0.79210365, -0.2973517 ,  0.5713881 ,  0.80937624,  0.26412377,\n",
       "        -0.23860048, -0.5698415 ,  0.4754357 , -0.37739974, -0.2888611 ,\n",
       "         0.7993187 ,  0.20418134,  0.10416193, -0.21335675,  0.40395567,\n",
       "        -0.2945866 , -0.3966085 , -0.1795262 ,  0.29537657,  0.18283333,\n",
       "        -0.51157093,  0.45422292, -0.3831778 ,  0.283654  , -0.6227849 ,\n",
       "        -0.18738446,  0.13160704,  0.2287451 ,  0.2072142 ,  0.66303575,\n",
       "         0.61100894, -0.06949192,  0.24995966,  0.20548852, -0.66611797,\n",
       "        -0.72103673,  0.22210129, -0.13718398, -0.46139422, -0.12041768,\n",
       "         0.19188191, -0.02580469,  0.14191495,  0.35288373, -0.5483277 ,\n",
       "        -0.28772056,  0.39581707,  0.6901407 ]], dtype=float32)>, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d440c29d-479b-466d-b55d-2589a8f3918c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  110617344 \n",
      "=================================================================\n",
      "Total params: 110,617,344\n",
      "Trainable params: 110,617,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e26fc26d-42ba-4b46-ac02-8a06356f893a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 768])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['pooler_output'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "484b8134-f354-4265-ab09-c8e6540deebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_output = output['pooler_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2e0884e8-298c-4ff2-a1f8-b1f5ff604fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pooled_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0546fa7c-a485-423d-b178-ed88bd36434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_output_numpy_array = pooled_output.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1fde3f57-0c39-4a95-bf05-b5005425da59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pooled_output_numpy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e1cee265-f25c-4182-a53d-825c6cc6baf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_output_numpy_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fa3c09a1-0926-47ed-91d8-30491487edd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = \"ibu ku sedang bekerja di supermarket\"\n",
    "encoded_input_1 = tokenizer(text_1, return_tensors='tf')\n",
    "output_1 = model(encoded_input_1)\n",
    "\n",
    "text_2 = \"ibu ku sedang bekerja sebagai supermarket\"\n",
    "encoded_input_2 = tokenizer(text_2, return_tensors='tf')\n",
    "output_2 = model(encoded_input_2)\n",
    "                 \n",
    "text_3 = \"ibu ku sedang bekerja dengan supermarket\"\n",
    "encoded_input_3 = tokenizer(text_3, return_tensors='tf')\n",
    "output_3 = model(encoded_input_3)\n",
    "\n",
    "text_4 = \"Silakan diganti dengan text apa saja.\"\n",
    "encoded_input_4 = tokenizer(text_4, return_tensors='tf')\n",
    "output_4 = model(encoded_input_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0812eb0f-4b9c-471e-8d96-8202a9b582c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_output_numpy_array_1 = output_1['pooler_output'].numpy()\n",
    "pooled_output_numpy_array_2 = output_2['pooler_output'].numpy()\n",
    "pooled_output_numpy_array_3 = output_3['pooler_output'].numpy()\n",
    "pooled_output_numpy_array_4 = output_4['pooler_output'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "69ce7577-2a83-4258-94e1-4bda073a845e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_output_numpy_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d5ee5214-47eb-4345-8bfd-92aba8d3f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_numpy_array = np.array((pooled_output_numpy_array_2, pooled_output_numpy_array_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7d48577b-9e56-4204-ab1f-f375c4f01102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 768)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_numpy_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ba41ab2a-f986-4f66-910f-a90d51128674",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_array = target_numpy_array.reshape(2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1e431629-229e-486e-94f7-a906bfee6380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 768)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d81ba3a4-d052-4089-9c11-dd3df29b4040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99274313]], dtype=float32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(\n",
    "    pooled_output_numpy_array_1,\n",
    "    pooled_output_numpy_array_2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5eeef49f-7abf-4487-a55a-3145076d61c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99489963]], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(\n",
    "    pooled_output_numpy_array_1,\n",
    "    pooled_output_numpy_array_3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "932942ef-f871-4f93-852e-bc07e7881e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8794708]], dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(\n",
    "    pooled_output_numpy_array_1,\n",
    "    pooled_output_numpy_array_4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "62ae717a-c512-4739-82b9-70c14eaa0276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pooled_output_numpy_array_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319f562b-6b39-466e-878f-820e15483f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d75d9c-070a-46ad-8454-f7742c44cc6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe99e8ab-a13a-42c0-b45d-446056942b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4360ce-383e-4b0b-a95a-69888c97b17a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79740be2-678e-489b-b540-44bd79669910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c36366-29cf-4222-9ddf-f96e1078e2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4704083-d119-4351-ac18-2338cf60fa3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8636c7-44ee-487d-8e35-42311c0c21cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a16425-d58c-46a3-b0c5-840fd677ab63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cf38958a-e006-4adf-a1ce-6a0568626a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_array = np.array([1,2,3])\n",
    "target_arrays = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
    "dotted_product = np.dot(source_array, target_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c9f02b79-bb04-40e0-8733-e18c7cf6277d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 36, 42])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotted_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "50aea90a-1824-461b-8ee8-16342bdafb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1+8+21, 2+10+24, 3+12+27) - (30, 36, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af62b73-3e4c-4426-bc82-fd1fc3ab0473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6404816c-1b52-4d17-b582-193f81ac419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ae427a-9fc9-469c-bac3-f353a33c8b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(\n",
    "    [sentence_embeddings[0]],\n",
    "    sentence_embeddings[1:]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
